{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Credit Card Customers\n",
    "\n",
    "In this project, we will use data from a credit card company to build a binary classifier which predicts which customers will churn. The data can be obtained from [this dataset](https://www.kaggle.com/sakshigoyal7/credit-card-customers) on Kaggle. \n",
    "\n",
    "The author of the dataset gives an important note: if our model predicts non-churning customers as churning, it won't hurt the business. However, we do not want to make the opposite error of predicting churning customers as non-churning. So, we should allow our model to be *sensitive* at the price of being less precise. Thus we will measure the effectiveness of our model by measuring its **Recall**: \n",
    "$$ \\mathrm{Recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$$ \n",
    "where $\\mathrm{TP}$ and $\\mathrm{FN}$ denote the number of *true positives* and *false negatives* our model predicts on the validation set, assuming that \"churning\" is our positive class.  \n",
    "\n",
    "The author was able to build a model that achieved 62% recall. The task is to build a model which improves this number. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Loading\n",
    "\n",
    "The previous owner of the data makes a note that we should ignore or delete the last two columns of the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0              39  ...                       1                      3   \n",
       "1              44  ...                       1                      2   \n",
       "2              36  ...                       1                      0   \n",
       "3              34  ...                       4                      1   \n",
       "4              21  ...                       1                      0   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0       12691.0                  777          11914.0                 1.335   \n",
       "1        8256.0                  864           7392.0                 1.541   \n",
       "2        3418.0                    0           3418.0                 2.594   \n",
       "3        3313.0                 2517            796.0                 1.405   \n",
       "4        4716.0                    0           4716.0                 2.175   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1144              42                1.625                  0.061  \n",
       "1             1291              33                3.714                  0.105  \n",
       "2             1887              20                2.333                  0.000  \n",
       "3             1171              20                2.333                  0.760  \n",
       "4              816              28                2.500                  0.000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CLIENTNUM</th>\n      <th>Attrition_Flag</th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>...</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>768805383</td>\n      <td>Existing Customer</td>\n      <td>45</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>12691.0</td>\n      <td>777</td>\n      <td>11914.0</td>\n      <td>1.335</td>\n      <td>1144</td>\n      <td>42</td>\n      <td>1.625</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>818770008</td>\n      <td>Existing Customer</td>\n      <td>49</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>44</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8256.0</td>\n      <td>864</td>\n      <td>7392.0</td>\n      <td>1.541</td>\n      <td>1291</td>\n      <td>33</td>\n      <td>3.714</td>\n      <td>0.105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>713982108</td>\n      <td>Existing Customer</td>\n      <td>51</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>2.594</td>\n      <td>1887</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>769911858</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>F</td>\n      <td>4</td>\n      <td>High School</td>\n      <td>Unknown</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3313.0</td>\n      <td>2517</td>\n      <td>796.0</td>\n      <td>1.405</td>\n      <td>1171</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>709106358</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>21</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>2.175</td>\n      <td>816</td>\n      <td>28</td>\n      <td>2.500</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('BankChurners.csv').iloc[:,:-2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10127 entries, 0 to 10126\nData columns (total 21 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   CLIENTNUM                 10127 non-null  int64  \n 1   Attrition_Flag            10127 non-null  object \n 2   Customer_Age              10127 non-null  int64  \n 3   Gender                    10127 non-null  object \n 4   Dependent_count           10127 non-null  int64  \n 5   Education_Level           10127 non-null  object \n 6   Marital_Status            10127 non-null  object \n 7   Income_Category           10127 non-null  object \n 8   Card_Category             10127 non-null  object \n 9   Months_on_book            10127 non-null  int64  \n 10  Total_Relationship_Count  10127 non-null  int64  \n 11  Months_Inactive_12_mon    10127 non-null  int64  \n 12  Contacts_Count_12_mon     10127 non-null  int64  \n 13  Credit_Limit              10127 non-null  float64\n 14  Total_Revolving_Bal       10127 non-null  int64  \n 15  Avg_Open_To_Buy           10127 non-null  float64\n 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n 17  Total_Trans_Amt           10127 non-null  int64  \n 18  Total_Trans_Ct            10127 non-null  int64  \n 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n 20  Avg_Utilization_Ratio     10127 non-null  float64\ndtypes: float64(5), int64(10), object(6)\nmemory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CLIENTNUM                   0\n",
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "It appears that there is no null data, but further inspection shows that the null data has been changed to the string `'Unknown'`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CLIENTNUM                      0\n",
       "Attrition_Flag                 0\n",
       "Customer_Age                   0\n",
       "Gender                         0\n",
       "Dependent_count                0\n",
       "Education_Level             1519\n",
       "Marital_Status               749\n",
       "Income_Category             1112\n",
       "Card_Category                  0\n",
       "Months_on_book                 0\n",
       "Total_Relationship_Count       0\n",
       "Months_Inactive_12_mon         0\n",
       "Contacts_Count_12_mon          0\n",
       "Credit_Limit                   0\n",
       "Total_Revolving_Bal            0\n",
       "Avg_Open_To_Buy                0\n",
       "Total_Amt_Chng_Q4_Q1           0\n",
       "Total_Trans_Amt                0\n",
       "Total_Trans_Ct                 0\n",
       "Total_Ct_Chng_Q4_Q1            0\n",
       "Avg_Utilization_Ratio          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "unknown = df == 'Unknown'\n",
    "unknown.sum()"
   ]
  },
  {
   "source": [
    "## Feature Descriptions\n",
    "\n",
    "The `CLIENTNUM` column can probably be ignored since we can identify customers based on their row in the dataframe. The `Attrition_Flag` column provides the labels we will use for our supervised-learning task. There are 19 other columns which we are free to use as training data. \n",
    "\n",
    "* `Customer_Age`: Demographic variable - Customer's Age in Years.\n",
    "* `Gender`: Demographic variable - M=Male, F=Female.\n",
    "* `Dependent_count`: Demographic variable - Number of dependents\n",
    "* `Education_Level`: Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n",
    "* `Marital_Status`: Demographic variable - Married, Single, Divorced, Unknown.\n",
    "* `Income_Category`: Demographic variable - Annual Income Category of the account holder (< \\$40K, \\$40K - 60K, \\$60K - \\$80K, \\$80K-\\$120K, > \\$120k)\n",
    "* `Card_Category`: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n",
    "* `Months_on_book`: Period of relationship with bank.\n",
    "* `Total_Relationship_Count`: Total number of products held by the customer.\n",
    "* `Months_Inactive_12_mon`: Number of months inactive in the last 12 months.\n",
    "* `Contacts_Counts_12_mon`: Number of contacts in the last 12 months.\n",
    "* `Credit_Limit`: Credit limit on the credit card.\n",
    "* `Total_Revolving_Bal`: Total revolving balance on the credit card (the portion of credit card spending that goes unpaid at the end of a billing cycle).\n",
    "* `Avg_Open_To_Buy`: Open to buy credit line (Average of last 12 months). The difference between the credit limit assigned to a cardholder account and the present balance on the account.\n",
    "* `Total_Amt_Chng_Q4_Q1`: Change in transaction amount (Q4 over Q1).\n",
    "* `Total_Trans_Amt`: Total transaction amount (last 12 months).\n",
    "* `Total_trans_Ct`: Number of transactions (last 12 months).\n",
    "* `Total_Ct_Chng_Q4_Q1`: Change in transaction count (Q4 over Q1).\n",
    "* `Avg_Utilization_Ratio`: Average percentage of credit used with respect to the credit limit.\n",
    "\n",
    "We have 10,127 entries to work with, which should be plenty to get a good model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['CLIENTNUM'], inplace=True)\n",
    "\n",
    "# 'Attrited Customer' is the positive class\n",
    "df['Attrition_Flag'].replace({'Existing Customer' : 0, 'Attrited Customer' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.83934\n",
       "1    0.16066\n",
       "Name: Attrition_Flag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Customer churn is ~16%. \n",
    "df['Attrition_Flag'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "0             56      M                3         College        Married   \n",
       "1             42      F                2        Graduate        Unknown   \n",
       "2             46      M                3     High School        Married   \n",
       "3             50      F                3      Uneducated         Single   \n",
       "4             51      M                1      Uneducated        Married   \n",
       "5             64      F                0      Uneducated        Married   \n",
       "6             53      F                5        Graduate         Single   \n",
       "7             55      M                2         College        Married   \n",
       "8             37      M                2       Doctorate         Single   \n",
       "9             41      F                1     High School         Single   \n",
       "10            44      M                3     High School         Single   \n",
       "11            38      F                2      Uneducated        Married   \n",
       "12            44      M                4      Uneducated        Married   \n",
       "13            51      M                1       Doctorate        Married   \n",
       "14            45      M                4        Graduate         Single   \n",
       "15            58      F                4        Graduate        Married   \n",
       "16            34      M                2     High School         Single   \n",
       "17            62      F                0       Doctorate        Married   \n",
       "18            48      M                2        Graduate        Unknown   \n",
       "19            34      F                2        Graduate        Unknown   \n",
       "\n",
       "   Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "0          $120K +          Blue              43                         6   \n",
       "1          Unknown          Blue              34                         5   \n",
       "2     $80K - $120K          Blue              27                         4   \n",
       "3          Unknown          Blue              36                         2   \n",
       "4      $60K - $80K          Blue              38                         3   \n",
       "5          Unknown          Blue              54                         6   \n",
       "6      $40K - $60K          Blue              41                         2   \n",
       "7          $120K +          Blue              37                         5   \n",
       "8          $120K +          Blue              32                         3   \n",
       "9   Less than $40K          Blue              31                         4   \n",
       "10     $40K - $60K          Blue              34                         5   \n",
       "11  Less than $40K          Blue              36                         2   \n",
       "12    $80K - $120K        Silver              27                         4   \n",
       "13    $80K - $120K          Blue              44                         5   \n",
       "14    $80K - $120K          Blue              36                         6   \n",
       "15         Unknown          Blue              42                         3   \n",
       "16         Unknown          Blue              36                         3   \n",
       "17     $40K - $60K          Blue              51                         3   \n",
       "18     $40K - $60K          Blue              36                         5   \n",
       "19         Unknown        Silver              16                         2   \n",
       "\n",
       "    Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                        2                      2       17539.0   \n",
       "1                        2                      2       19373.0   \n",
       "2                        2                      3        4964.0   \n",
       "3                        3                      3        3187.0   \n",
       "4                        3                      1       13731.0   \n",
       "5                        1                      2        3250.0   \n",
       "6                        1                      3        9815.0   \n",
       "7                        2                      3       32641.0   \n",
       "8                        3                      5       32056.0   \n",
       "9                        2                      1        1998.0   \n",
       "10                       3                      1        8997.0   \n",
       "11                       3                      2        7825.0   \n",
       "12                       3                      2       34516.0   \n",
       "13                       2                      4        8031.0   \n",
       "14                       3                      1        8063.0   \n",
       "15                       3                      4       10247.0   \n",
       "16                       4                      2       22886.0   \n",
       "17                       3                      2        3377.0   \n",
       "18                       1                      2       13068.0   \n",
       "19                       2                      1       32292.0   \n",
       "\n",
       "    Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0                  2517          15022.0                 0.743   \n",
       "1                  1142          18231.0                 0.655   \n",
       "2                  2316           2648.0                 0.793   \n",
       "3                   986           2201.0                 0.615   \n",
       "4                  1375          12356.0                 0.878   \n",
       "5                  1992           1258.0                 0.715   \n",
       "6                  1699           8116.0                 0.620   \n",
       "7                  1551          31090.0                 0.488   \n",
       "8                  1887          30169.0                 0.831   \n",
       "9                     0           1998.0                 0.717   \n",
       "10                  708           8289.0                 0.586   \n",
       "11                    0           7825.0                 0.724   \n",
       "12                 1043          33473.0                 0.690   \n",
       "13                 1167           6864.0                 0.549   \n",
       "14                 1485           6578.0                 0.872   \n",
       "15                 1600           8647.0                 0.630   \n",
       "16                  836          22050.0                 0.889   \n",
       "17                  948           2429.0                 0.461   \n",
       "18                 1718          11350.0                 0.607   \n",
       "19                 1731          30561.0                 0.751   \n",
       "\n",
       "    Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0              1220              30                0.765   \n",
       "1              1792              48                0.455   \n",
       "2              3279              66                0.941   \n",
       "3              2381              47                0.516   \n",
       "4             14826              99                0.707   \n",
       "5              1355              36                0.565   \n",
       "6              7962              89                0.561   \n",
       "7              1327              30                0.304   \n",
       "8              2730              68                0.700   \n",
       "9              4637              68                0.889   \n",
       "10             4558              62                0.676   \n",
       "11            14326             100                0.786   \n",
       "12             4654              59                0.639   \n",
       "13             3576              77                0.791   \n",
       "14             4275              77                0.833   \n",
       "15             1754              44                0.692   \n",
       "16             2652              61                0.743   \n",
       "17             1407              44                0.467   \n",
       "18              937              28                0.556   \n",
       "19             7564              76                0.810   \n",
       "\n",
       "    Avg_Utilization_Ratio  \n",
       "0                   0.144  \n",
       "1                   0.059  \n",
       "2                   0.467  \n",
       "3                   0.309  \n",
       "4                   0.100  \n",
       "5                   0.613  \n",
       "6                   0.173  \n",
       "7                   0.048  \n",
       "8                   0.059  \n",
       "9                   0.000  \n",
       "10                  0.079  \n",
       "11                  0.000  \n",
       "12                  0.030  \n",
       "13                  0.145  \n",
       "14                  0.184  \n",
       "15                  0.156  \n",
       "16                  0.037  \n",
       "17                  0.281  \n",
       "18                  0.131  \n",
       "19                  0.054  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>M</td>\n      <td>3</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>43</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>17539.0</td>\n      <td>2517</td>\n      <td>15022.0</td>\n      <td>0.743</td>\n      <td>1220</td>\n      <td>30</td>\n      <td>0.765</td>\n      <td>0.144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>19373.0</td>\n      <td>1142</td>\n      <td>18231.0</td>\n      <td>0.655</td>\n      <td>1792</td>\n      <td>48</td>\n      <td>0.455</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>27</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4964.0</td>\n      <td>2316</td>\n      <td>2648.0</td>\n      <td>0.793</td>\n      <td>3279</td>\n      <td>66</td>\n      <td>0.941</td>\n      <td>0.467</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>F</td>\n      <td>3</td>\n      <td>Uneducated</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3187.0</td>\n      <td>986</td>\n      <td>2201.0</td>\n      <td>0.615</td>\n      <td>2381</td>\n      <td>47</td>\n      <td>0.516</td>\n      <td>0.309</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>38</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13731.0</td>\n      <td>1375</td>\n      <td>12356.0</td>\n      <td>0.878</td>\n      <td>14826</td>\n      <td>99</td>\n      <td>0.707</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>64</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>54</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3250.0</td>\n      <td>1992</td>\n      <td>1258.0</td>\n      <td>0.715</td>\n      <td>1355</td>\n      <td>36</td>\n      <td>0.565</td>\n      <td>0.613</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>53</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9815.0</td>\n      <td>1699</td>\n      <td>8116.0</td>\n      <td>0.620</td>\n      <td>7962</td>\n      <td>89</td>\n      <td>0.561</td>\n      <td>0.173</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>55</td>\n      <td>M</td>\n      <td>2</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>37</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>32641.0</td>\n      <td>1551</td>\n      <td>31090.0</td>\n      <td>0.488</td>\n      <td>1327</td>\n      <td>30</td>\n      <td>0.304</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Doctorate</td>\n      <td>Single</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>32</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>32056.0</td>\n      <td>1887</td>\n      <td>30169.0</td>\n      <td>0.831</td>\n      <td>2730</td>\n      <td>68</td>\n      <td>0.700</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>F</td>\n      <td>1</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1998.0</td>\n      <td>0</td>\n      <td>1998.0</td>\n      <td>0.717</td>\n      <td>4637</td>\n      <td>68</td>\n      <td>0.889</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8997.0</td>\n      <td>708</td>\n      <td>8289.0</td>\n      <td>0.586</td>\n      <td>4558</td>\n      <td>62</td>\n      <td>0.676</td>\n      <td>0.079</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7825.0</td>\n      <td>0</td>\n      <td>7825.0</td>\n      <td>0.724</td>\n      <td>14326</td>\n      <td>100</td>\n      <td>0.786</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Silver</td>\n      <td>27</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>34516.0</td>\n      <td>1043</td>\n      <td>33473.0</td>\n      <td>0.690</td>\n      <td>4654</td>\n      <td>59</td>\n      <td>0.639</td>\n      <td>0.030</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>44</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8031.0</td>\n      <td>1167</td>\n      <td>6864.0</td>\n      <td>0.549</td>\n      <td>3576</td>\n      <td>77</td>\n      <td>0.791</td>\n      <td>0.145</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8063.0</td>\n      <td>1485</td>\n      <td>6578.0</td>\n      <td>0.872</td>\n      <td>4275</td>\n      <td>77</td>\n      <td>0.833</td>\n      <td>0.184</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>58</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>42</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>10247.0</td>\n      <td>1600</td>\n      <td>8647.0</td>\n      <td>0.630</td>\n      <td>1754</td>\n      <td>44</td>\n      <td>0.692</td>\n      <td>0.156</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>34</td>\n      <td>M</td>\n      <td>2</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>22886.0</td>\n      <td>836</td>\n      <td>22050.0</td>\n      <td>0.889</td>\n      <td>2652</td>\n      <td>61</td>\n      <td>0.743</td>\n      <td>0.037</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>62</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>51</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3377.0</td>\n      <td>948</td>\n      <td>2429.0</td>\n      <td>0.461</td>\n      <td>1407</td>\n      <td>44</td>\n      <td>0.467</td>\n      <td>0.281</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>48</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13068.0</td>\n      <td>1718</td>\n      <td>11350.0</td>\n      <td>0.607</td>\n      <td>937</td>\n      <td>28</td>\n      <td>0.556</td>\n      <td>0.131</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>34</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Silver</td>\n      <td>16</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>32292.0</td>\n      <td>1731</td>\n      <td>30561.0</td>\n      <td>0.751</td>\n      <td>7564</td>\n      <td>76</td>\n      <td>0.810</td>\n      <td>0.054</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Split data into training and testing sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=808)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_y = train_df['Attrition_Flag']\n",
    "test_y = test_df['Attrition_Flag']\n",
    "\n",
    "train_X = train_df.drop(columns=['Attrition_Flag'])\n",
    "test_X = test_df.drop(columns=['Attrition_Flag'])\n",
    "\n",
    "train_X.iloc[0:20, :]"
   ]
  },
  {
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "Our data enjoys five different features whose values are represented as strings. We should encode these into numeric data before moving on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Education_Level',\n",
       " 'Marital_Status',\n",
       " 'Income_Category',\n",
       " 'Card_Category']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from pandas.api.types import is_object_dtype\n",
    "\n",
    "obj_cols = [c for c in train_X.columns if is_object_dtype(train_X[c])]\n",
    "obj_cols"
   ]
  },
  {
   "source": [
    "## Gender\n",
    "\n",
    "Unfortunately, the data only has two gender values. It is possible that customers of non-binary gender have significantly different attrition rates, but instead we will have to work within the very coarse framework given to us.\n",
    "\n",
    "Integer encoding and one hot encoding are equivalent for a binary variable, so either one will work. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "F    0.533144\n",
       "M    0.466856\n",
       "Name: Gender, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_X['Gender'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "## Education Level\n",
    "\n",
    "The values are ordered since the education levels follow a linear path, except that we have an `'Unknown'` value. We do not know why certain entries are labeled this way. We will assume it's because the customers chose not to provide this information, in which case this may be a useful category to keep. We will worry about these values later.\n",
    "\n",
    "We will use integer encoding for this feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Graduate         0.309098\n",
       "High School      0.202074\n",
       "Unknown          0.148747\n",
       "Uneducated       0.143563\n",
       "College          0.098136\n",
       "Post-Graduate    0.051352\n",
       "Doctorate        0.047031\n",
       "Name: Education_Level, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_X['Education_Level'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "## Marital Status\n",
    "\n",
    "There is no linear ordering on these values. We will worry about ther `'Unknown'` values later.\n",
    "\n",
    "We will use one hot encoding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Married     0.463400\n",
       "Single      0.390693\n",
       "Divorced    0.073201\n",
       "Unknown     0.072707\n",
       "Name: Marital_Status, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_X['Marital_Status'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "## Income Category\n",
    "\n",
    "The income categories may be sensibly ordered from smallest to largest. We will worry about the `'Unknown'` values later.\n",
    "\n",
    "We will use integer encoding, from smallest to largest income. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Less than $40K    0.350697\n",
       "$40K - $60K       0.176892\n",
       "$80K - $120K      0.147513\n",
       "$60K - $80K       0.139119\n",
       "Unknown           0.114924\n",
       "$120K +           0.070855\n",
       "Name: Income_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_X['Income_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "## Card Category\n",
    "\n",
    "I will make the assumption that the card categories are ordered such that \n",
    "$$ \\textrm{Blue} < \\textrm{Silver} < \\textrm{Gold} < \\textrm{Platinum}.$$\n",
    "The value counts for this feature gives evidence for this ordering."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Blue        0.932107\n",
       "Silver      0.054685\n",
       "Gold        0.011357\n",
       "Platinum    0.001852\n",
       "Name: Card_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_X['Card_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "## Summary\n",
    "\n",
    "We will bundle these encodings together into one column-transformer which we will later use in a pipeline. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "encoder = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), \n",
    "        ['Gender', 'Marital_Status']),\n",
    "    (OrdinalEncoder(categories=[\n",
    "            ['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'],\n",
    "            ['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'],\n",
    "            ['Blue', 'Silver', 'Gold', 'Platinum']]), \n",
    "        ['Education_Level', 'Income_Category', 'Card_Category']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "source": [
    "# Dealing With Missing Data\n",
    "\n",
    "Recall that our `'Education_Level'`, `'Marital_Status'`, and `'Income_Category'` features contained a good amount of missing data. We will assume that this is not completely random; it may be the case that the customers willingly refused to provide this information to us. In this case, the missing data may be considered as data itself. \n",
    "\n",
    "We must make a choice for how to deal with this missing data. It would be nice if, at this step, we could fill in missing data intelligently without deleting any information. We may consider deleting features at a later step during feature selection.\n",
    "\n",
    "First, we will create two new features `'Gave_Education'`, `'Gave_Marital_Status'` and `'Gave_Income'` which has value `'False'` if the corresponding feature is `'Unknown'`. Otherwise, it has value `'True'`.\n",
    "\n",
    "After this, we will train a machine learning algorithm on the data without missing values to predict what the missing values might be."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating New Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "8096            37      M                3     High School         Single   \n",
       "8097            44      F                2         College        Married   \n",
       "8098            33      F                4         College         Single   \n",
       "8099            50      F                4       Doctorate        Married   \n",
       "8100            65      F                0      Uneducated         Single   \n",
       "\n",
       "     Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "8096    $80K - $120K          Blue              31                         4   \n",
       "8097     $40K - $60K          Blue              39                         4   \n",
       "8098  Less than $40K          Blue              36                         1   \n",
       "8099         Unknown        Silver              36                         3   \n",
       "8100  Less than $40K          Blue              50                         3   \n",
       "\n",
       "      Months_Inactive_12_mon  ...  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "8096                       2  ...                 1006           4693.0   \n",
       "8097                       1  ...                  775            926.0   \n",
       "8098                       3  ...                    0           1438.3   \n",
       "8099                       2  ...                 2096          32420.0   \n",
       "8100                       4  ...                  377           1320.0   \n",
       "\n",
       "      Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "8096                 0.734             2835              57   \n",
       "8097                 0.847             4471              71   \n",
       "8098                 0.566             4641              85   \n",
       "8099                 0.666             7042              73   \n",
       "8100                 1.048             2799              49   \n",
       "\n",
       "      Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Gave_Education  \\\n",
       "8096                0.900                  0.177            True   \n",
       "8097                0.614                  0.456            True   \n",
       "8098                0.700                  0.000            True   \n",
       "8099                0.553                  0.061            True   \n",
       "8100                0.485                  0.222            True   \n",
       "\n",
       "      Gave_Marital_Status  Gave_Income  \n",
       "8096                 True         True  \n",
       "8097                 True         True  \n",
       "8098                 True         True  \n",
       "8099                 True        False  \n",
       "8100                 True         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>...</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n      <th>Gave_Education</th>\n      <th>Gave_Marital_Status</th>\n      <th>Gave_Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8096</th>\n      <td>37</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1006</td>\n      <td>4693.0</td>\n      <td>0.734</td>\n      <td>2835</td>\n      <td>57</td>\n      <td>0.900</td>\n      <td>0.177</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8097</th>\n      <td>44</td>\n      <td>F</td>\n      <td>2</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>775</td>\n      <td>926.0</td>\n      <td>0.847</td>\n      <td>4471</td>\n      <td>71</td>\n      <td>0.614</td>\n      <td>0.456</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8098</th>\n      <td>33</td>\n      <td>F</td>\n      <td>4</td>\n      <td>College</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1438.3</td>\n      <td>0.566</td>\n      <td>4641</td>\n      <td>85</td>\n      <td>0.700</td>\n      <td>0.000</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8099</th>\n      <td>50</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Silver</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2096</td>\n      <td>32420.0</td>\n      <td>0.666</td>\n      <td>7042</td>\n      <td>73</td>\n      <td>0.553</td>\n      <td>0.061</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8100</th>\n      <td>65</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Uneducated</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>50</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>377</td>\n      <td>1320.0</td>\n      <td>1.048</td>\n      <td>2799</td>\n      <td>49</td>\n      <td>0.485</td>\n      <td>0.222</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_X['Gave_Education'] = train_X['Education_Level'] != 'Unknown'\n",
    "test_X['Gave_Education'] = test_X['Education_Level'] != 'Unknown'\n",
    "\n",
    "train_X['Gave_Marital_Status'] = train_X['Marital_Status'] != 'Unknown'\n",
    "test_X['Gave_Marital_Status'] = test_X['Marital_Status'] != 'Unknown'\n",
    "\n",
    "train_X['Gave_Income'] = train_X['Income_Category'] != 'Unknown'\n",
    "test_X['Gave_Income'] = test_X['Income_Category'] != 'Unknown'\n",
    "\n",
    "train_X.tail()"
   ]
  },
  {
   "source": [
    "## Prepping Data for Imputer Model\n",
    "\n",
    "Note that we won't use the features we've just created above. They would all be constant since we are restricting to data with no missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows:  5658\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "not_missing_df = train_df[(train_df['Education_Level'] != 'Unknown') &\n",
    "                          (train_df['Marital_Status']  != 'Unknown') &\n",
    "                          (train_df['Income_Category'] != 'Unknown')  ].copy()\n",
    "\n",
    "print('Number of rows: ', len(not_missing_df))\n",
    "unknown = not_missing_df == 'Unknown'\n",
    "unknown.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Customer_Age Gender  Dependent_count Card_Category  Months_on_book  \\\n",
       "0             56      M                3          Blue              43   \n",
       "2             46      M                3          Blue              27   \n",
       "4             51      M                1          Blue              38   \n",
       "6             53      F                5          Blue              41   \n",
       "7             55      M                2          Blue              37   \n",
       "8             37      M                2          Blue              32   \n",
       "9             41      F                1          Blue              31   \n",
       "10            44      M                3          Blue              34   \n",
       "11            38      F                2          Blue              36   \n",
       "12            44      M                4        Silver              27   \n",
       "\n",
       "    Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                          6                       2                      2   \n",
       "2                          4                       2                      3   \n",
       "4                          3                       3                      1   \n",
       "6                          2                       1                      3   \n",
       "7                          5                       2                      3   \n",
       "8                          3                       3                      5   \n",
       "9                          4                       2                      1   \n",
       "10                         5                       3                      1   \n",
       "11                         2                       3                      2   \n",
       "12                         4                       3                      2   \n",
       "\n",
       "    Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0        17539.0                 2517          15022.0                 0.743   \n",
       "2         4964.0                 2316           2648.0                 0.793   \n",
       "4        13731.0                 1375          12356.0                 0.878   \n",
       "6         9815.0                 1699           8116.0                 0.620   \n",
       "7        32641.0                 1551          31090.0                 0.488   \n",
       "8        32056.0                 1887          30169.0                 0.831   \n",
       "9         1998.0                    0           1998.0                 0.717   \n",
       "10        8997.0                  708           8289.0                 0.586   \n",
       "11        7825.0                    0           7825.0                 0.724   \n",
       "12       34516.0                 1043          33473.0                 0.690   \n",
       "\n",
       "    Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0              1220              30                0.765   \n",
       "2              3279              66                0.941   \n",
       "4             14826              99                0.707   \n",
       "6              7962              89                0.561   \n",
       "7              1327              30                0.304   \n",
       "8              2730              68                0.700   \n",
       "9              4637              68                0.889   \n",
       "10             4558              62                0.676   \n",
       "11            14326             100                0.786   \n",
       "12             4654              59                0.639   \n",
       "\n",
       "    Avg_Utilization_Ratio  \n",
       "0                   0.144  \n",
       "2                   0.467  \n",
       "4                   0.100  \n",
       "6                   0.173  \n",
       "7                   0.048  \n",
       "8                   0.059  \n",
       "9                   0.000  \n",
       "10                  0.079  \n",
       "11                  0.000  \n",
       "12                  0.030  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>43</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>17539.0</td>\n      <td>2517</td>\n      <td>15022.0</td>\n      <td>0.743</td>\n      <td>1220</td>\n      <td>30</td>\n      <td>0.765</td>\n      <td>0.144</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>27</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4964.0</td>\n      <td>2316</td>\n      <td>2648.0</td>\n      <td>0.793</td>\n      <td>3279</td>\n      <td>66</td>\n      <td>0.941</td>\n      <td>0.467</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Blue</td>\n      <td>38</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13731.0</td>\n      <td>1375</td>\n      <td>12356.0</td>\n      <td>0.878</td>\n      <td>14826</td>\n      <td>99</td>\n      <td>0.707</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>53</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Blue</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9815.0</td>\n      <td>1699</td>\n      <td>8116.0</td>\n      <td>0.620</td>\n      <td>7962</td>\n      <td>89</td>\n      <td>0.561</td>\n      <td>0.173</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>55</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>37</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>32641.0</td>\n      <td>1551</td>\n      <td>31090.0</td>\n      <td>0.488</td>\n      <td>1327</td>\n      <td>30</td>\n      <td>0.304</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>32</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>32056.0</td>\n      <td>1887</td>\n      <td>30169.0</td>\n      <td>0.831</td>\n      <td>2730</td>\n      <td>68</td>\n      <td>0.700</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>F</td>\n      <td>1</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1998.0</td>\n      <td>0</td>\n      <td>1998.0</td>\n      <td>0.717</td>\n      <td>4637</td>\n      <td>68</td>\n      <td>0.889</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8997.0</td>\n      <td>708</td>\n      <td>8289.0</td>\n      <td>0.586</td>\n      <td>4558</td>\n      <td>62</td>\n      <td>0.676</td>\n      <td>0.079</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7825.0</td>\n      <td>0</td>\n      <td>7825.0</td>\n      <td>0.724</td>\n      <td>14326</td>\n      <td>100</td>\n      <td>0.786</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Silver</td>\n      <td>27</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>34516.0</td>\n      <td>1043</td>\n      <td>33473.0</td>\n      <td>0.690</td>\n      <td>4654</td>\n      <td>59</td>\n      <td>0.639</td>\n      <td>0.030</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "not_missing_X = not_missing_df.drop(columns=['Attrition_Flag', 'Education_Level', 'Marital_Status', 'Income_Category'], axis='columns')\n",
    "not_missing_y1 = not_missing_df['Education_Level']\n",
    "not_missing_y2 = not_missing_df['Marital_Status']\n",
    "not_missing_y3 = not_missing_df['Income_Category']\n",
    "\n",
    "not_missing_X.iloc[:10, :]"
   ]
  },
  {
   "source": [
    "## Training An Imputer Model\n",
    "\n",
    "Let's try a few different methods of imputing and pick the ones which have the best accuracy. We won't spend too much of our effort here since it is not the main task, but we will try a few different methods and pick the one which has the highest accuracy.\n",
    "\n",
    "First, let's get a baseline accuracy by just picking the most common categories for each feature. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most common education level: Graduate\nAccuracy: 0.36\n\nMost common marital status: Married\nAccuracy: 0.50\n\nMost common income category: Less than $40K\nAccuracy: 0.40\n\n"
     ]
    }
   ],
   "source": [
    "mode1 = not_missing_df['Education_Level'].mode()[0]\n",
    "mode2 = not_missing_df['Marital_Status'].mode()[0]\n",
    "mode3 = not_missing_df['Income_Category'].mode()[0]\n",
    "\n",
    "mode_score_1 = not_missing_df['Education_Level'].value_counts(normalize=True)[0]\n",
    "mode_score_2 = not_missing_df['Marital_Status'].value_counts(normalize=True)[0]\n",
    "mode_score_3 = not_missing_df['Income_Category'].value_counts(normalize=True)[0]\n",
    "\n",
    "print(f'Most common education level: {mode1}')\n",
    "print(f'Accuracy: {mode_score_1:.2f}\\n')\n",
    "print(f'Most common marital status: {mode2}')\n",
    "print(f'Accuracy: {mode_score_2:.2f}\\n')\n",
    "print(f'Most common income category: {mode3}')\n",
    "print(f'Accuracy: {mode_score_3:.2f}\\n')"
   ]
  },
  {
   "source": [
    "### Random Forest Imputer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# This encoder is a restriction of the one we constructed above.\n",
    "imputer_encoder = make_column_transformer(\n",
    "                                (OneHotEncoder(drop='first'), \n",
    "                                 ['Gender']),\n",
    "                                (OrdinalEncoder(categories=[['Blue', 'Silver', 'Gold', 'Platinum']]), \n",
    "                                 ['Card_Category']),\n",
    "                                remainder='passthrough')\n",
    "\n",
    "forest1 = RandomForestClassifier(random_state=808)\n",
    "forest2 = RandomForestClassifier(random_state=808)\n",
    "forest3 = RandomForestClassifier(random_state=808)\n",
    "\n",
    "param_grid = {'forest__n_estimators':range(1, 50),\n",
    "              'forest__max_depth':range(1, 20),\n",
    "              'forest__max_features':range(1, 10)}\n",
    "\n",
    "forest_pipe1 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest1)])\n",
    "forest_pipe2 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest2)])\n",
    "forest_pipe3 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest3)])\n",
    "\n",
    "forest_grid1 = RandomizedSearchCV(forest_pipe1, param_grid, cv=5, scoring='accuracy')\n",
    "forest_grid2 = RandomizedSearchCV(forest_pipe2, param_grid, cv=5, scoring='accuracy')\n",
    "forest_grid3 = RandomizedSearchCV(forest_pipe3, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "forest_grid1.fit(not_missing_X, not_missing_y1)\n",
    "forest_grid2.fit(not_missing_X, not_missing_y2)\n",
    "forest_grid3.fit(not_missing_X, not_missing_y3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_score1 = forest_grid1.best_score_\n",
    "forest_score2 = forest_grid2.best_score_\n",
    "forest_score3 = forest_grid3.best_score_\n",
    "\n",
    "forest_params1 = forest_grid1.best_params_\n",
    "forest_params2 = forest_grid2.best_params_\n",
    "forest_params3 = forest_grid3.best_params_\n",
    "\n",
    "print(f'Education Level\\nAccuracy: {forest_score1:.2f}\\nBest params: {forest_params1}\\n')\n",
    "print(f'Marital Status\\nAccuracy: {forest_score2:.2f}\\nBest params: {forest_params2}\\n')\n",
    "print(f'Income Category\\nAccuracy: {forest_score3:.2f}\\nBest params: {forest_params3}\\n')"
   ]
  },
  {
   "source": [
    "### $k$-Nearest Neighbors Imputer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier()\n",
    "knn2 = KNeighborsClassifier()\n",
    "knn3 = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'knn__n_neighbors' : range(1, 30)}\n",
    "\n",
    "knn_pipe1 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('knn', knn1)])\n",
    "knn_pipe2 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('knn', knn2)])\n",
    "knn_pipe3 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('knn', knn3)])\n",
    "\n",
    "knn_grid1 = GridSearchCV(knn_pipe1, param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid2 = GridSearchCV(knn_pipe2, param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid3 = GridSearchCV(knn_pipe3, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "knn_grid1.fit(not_missing_X, not_missing_y1)\n",
    "knn_grid2.fit(not_missing_X, not_missing_y2)\n",
    "knn_grid3.fit(not_missing_X, not_missing_y3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Education Level\nAccuracy: 0.34\nBest params: {'knn__n_neighbors': 28}\n\nMarital Status\nAccuracy: 0.54\nBest params: {'knn__n_neighbors': 17}\n\nIncome Category\nAccuracy: 0.56\nBest params: {'knn__n_neighbors': 29}\n\n"
     ]
    }
   ],
   "source": [
    "knn_score1 = knn_grid1.best_score_\n",
    "knn_score2 = knn_grid2.best_score_\n",
    "knn_score3 = knn_grid3.best_score_\n",
    "\n",
    "knn_params1 = knn_grid1.best_params_\n",
    "knn_params2 = knn_grid2.best_params_\n",
    "knn_params3 = knn_grid3.best_params_\n",
    "\n",
    "print(f'Education Level\\nAccuracy: {knn_score1:.2f}\\nBest params: {knn_params1}\\n')\n",
    "print(f'Marital Status\\nAccuracy: {knn_score2:.2f}\\nBest params: {knn_params2}\\n')\n",
    "print(f'Income Category\\nAccuracy: {knn_score3:.2f}\\nBest params: {knn_params3}\\n')"
   ]
  },
  {
   "source": [
    "It looks like imputing with a random forest classifier is the way to go. For now, we will say this is good enough for our purposes. One possible improvement would be to try XGBoost, which can be seen as a more sophisticated version of a Random Forest (they are both ensemble methods based on decision trees). Another option would be to use some dimensionality reduction techniques beforehand. Finally, we might get better results if we trained the three models in sequence instead of training them in parallel."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imputing With Random Forest Classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(random_state=808, n_estimators=25, max_features=6, max_depth=1)\n",
    "forest2 = RandomForestClassifier(random_state=808, n_estimators=31, max_features=9, max_depth=18)\n",
    "forest3 = RandomForestClassifier(random_state=808, n_estimators=31, max_features=9, max_depth=12)\n",
    "\n",
    "forest_pipe1 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest1)])\n",
    "forest_pipe2 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest2)])\n",
    "forest_pipe3 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest3)])\n",
    "\n",
    "forest_pipe1.fit(not_missing_X, not_missing_y1)\n",
    "forest_pipe2.fit(not_missing_X, not_missing_y2)\n",
    "forest_pipe3.fit(not_missing_X, not_missing_y3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_X1 = train_X.loc[(train_X.Education_Level == 'Unknown')].drop(labels=['Education_Level', 'Marital_Status', 'Income_Category'], axis='columns')\n",
    "missing_X2 = train_X.loc[(train_X.Marital_Status == 'Unknown')].drop(labels=['Education_Level', 'Marital_Status', 'Income_Category'], axis='columns')\n",
    "missing_X3 = train_X.loc[(train_X.Income_Category == 'Unknown')].drop(labels=['Education_Level', 'Marital_Status', 'Income_Category'], axis='columns')\n",
    "\n",
    "\n",
    "y_hat1 = forest_pipe1.predict(missing_X1)\n",
    "y_hat2 = forest_pipe2.predict(missing_X2)\n",
    "y_hat3 = forest_pipe3.predict(missing_X3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc[train_X.Education_Level == 'Unknown', 'Education_Level'] = y_hat1\n",
    "train_X.loc[train_X.Marital_Status == 'Unknown', 'Marital_Status'] = y_hat2\n",
    "train_X.loc[train_X.Income_Category == 'Unknown', 'Income_Category'] = y_hat3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8101, 22)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Less than $40K    3433\n",
       "$40K - $60K       1742\n",
       "$80K - $120K      1208\n",
       "$60K - $80K       1144\n",
       "$120K +            574\n",
       "Name: Income_Category, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Check to see that it worked.\n",
    "print(train_X.shape)\n",
    "train_X.Income_Category.value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "## Baseline Model\n",
    "\n",
    "Let's quickly train a logistic regression model to get a good baseline before we start using dimensionality reduction techniques. This way, we will be able to run sanity checks and see if our tehcniques are working towards improving the model or not."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=808)\n",
    "logreg_clf = Pipeline([('encoder', encoder), ('scaler', scaler), ('logreg', logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5900763358778626"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(logreg_clf, train_X, train_y, scoring='recall', cv=10).mean()"
   ]
  },
  {
   "source": [
    "# Feature Selection\n",
    "\n",
    "Here, we will attempt to apply some dimensionality reduction techniques, with a focus on maintaining the explainability of our future model. At the core, our task is to solve a binary classification problem using a mix of categorical and numerical data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Univariate Analysis\n",
    "\n",
    "We will compare each of our features to our target variable. If the feature is of integer type, we will apply the $\\chi^2$ test. For features of float type, we will perform an Analysis of Variance (ANOVA)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Customer_Age counts: \n 28     25\n32     82\n36    175\n40    282\n44    403\n48    381\n52    310\n56    208\n60     94\n64     33\n68      2\n29     51\n33     99\n37    217\n41    288\n45    393\n49    394\n53    308\n57    176\n61     73\n65     81\n73      1\n26     69\n30     58\n34    107\n38    240\n42    344\n46    389\n50    354\n54    239\n58    132\n62     78\n66      2\n70      1\n27     27\n31     72\n35    155\n39    278\n43    382\n47    384\n51    321\n55    216\n59    119\n63     55\n67      3\nName: Customer_Age, dtype: int64\nDependent_count counts: \n 0     735\n4    1282\n1    1487\n5     336\n2    2069\n3    2192\nName: Dependent_count, dtype: int64\nMonths_on_book counts: \n 16      25\n20      64\n24     127\n28     231\n32     233\n36    1981\n40     270\n44     185\n48     124\n52      45\n56      80\n13      59\n17      30\n21      68\n25     133\n29     185\n33     240\n37     297\n41     229\n45     176\n49     104\n53      68\n14      13\n18      48\n22      81\n26     144\n30     240\n34     269\n38     273\n42     225\n46     170\n50      75\n54      43\n15      28\n19      53\n23      93\n27     166\n31     253\n35     253\n39     282\n43     215\n47     134\n51      57\n55      32\nName: Months_on_book, dtype: int64\nTotal_Relationship_Count counts: \n 4    1547\n1     730\n5    1508\n2    1008\n6    1495\n3    1813\nName: Total_Relationship_Count, dtype: int64\nMonths_Inactive_12_mon counts: \n 0      23\n4     345\n1    1773\n5     144\n2    2634\n6      94\n3    3088\nName: Months_Inactive_12_mon, dtype: int64\nContacts_Count_12_mon counts: \n 0     318\n4    1142\n1    1186\n5     142\n2    2574\n6      41\n3    2698\nName: Contacts_Count_12_mon, dtype: int64\nTotal_Revolving_Bal counts: \n 0       1972\n2049       4\n2053       4\n2057       5\n2061       4\n        ... \n2031       3\n2035       4\n2039       2\n2043       4\n2047       4\nName: Total_Revolving_Bal, Length: 1900, dtype: int64\nTotal_Trans_Amt counts: \n 8192     1\n4098     4\n2053     3\n4102     1\n12920    1\n        ..\n4086     1\n7546     1\n2043     2\n4094     2\n9451     1\nName: Total_Trans_Amt, Length: 4476, dtype: int64\nTotal_Trans_Ct counts: \n 12      3\n16     12\n20     13\n24     39\n28     59\n       ..\n119    11\n123    11\n127     8\n131     6\n139     1\nName: Total_Trans_Ct, Length: 125, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_integer_dtype\n",
    "\n",
    "int_cols = [c for c in train_X.columns if is_integer_dtype(train_X[c])]\n",
    "\n",
    "for feature in int_cols:\n",
    "    val_cts = train_X[feature].value_counts(sort=False)\n",
    "    print(f'{feature} counts: \\n {val_cts}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000024DFFA47F48>"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "train_df.groupby(by='Attrition_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p-value Statistics:\n\nCustomer_Age: 0.04\nFeature is probably independent of target: False\n\nDependent_count: 0.03\nFeature is probably independent of target: False\n\nMonths_on_book: 0.09\nFeature is probably independent of target: True\n\nTotal_Relationship_Count: 0.00\nFeature is probably independent of target: False\n\nMonths_Inactive_12_mon: 0.00\nFeature is probably independent of target: False\n\nContacts_Count_12_mon: 0.00\nFeature is probably independent of target: False\n\nTotal_Revolving_Bal: 0.00\nFeature is probably independent of target: False\n\nTotal_Trans_Amt: 0.00\nFeature is probably independent of target: False\n\nTotal_Trans_Ct: 0.00\nFeature is probably independent of target: False\n\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_values = chi2(train_X[int_cols], train_y)[1]\n",
    "p_values_dict = {}\n",
    "col_filter = {}\n",
    "\n",
    "print('p-value Statistics:\\n')\n",
    "for i in range(len(int_cols)):\n",
    "    feature = int_cols[i]\n",
    "    p = p_values[i]\n",
    "    p_val_dict[feature] = p\n",
    "\n",
    "    print(f'{feature}: {p:.2f}')\n",
    "\n",
    "    is_independent = False if p <= alpha else True\n",
    "    col_filter[feature] = not is_independent    # Will throw away features which are independent from the target.\n",
    "\n",
    "    print(f'Feature is probably independent of target: {is_independent}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}