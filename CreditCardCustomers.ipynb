{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Credit Card Customers\n",
    "\n",
    "In this project, we will use data from a credit card company to build a binary classifier which predicts which customers will churn. The data can be obtained from [this dataset](https://www.kaggle.com/sakshigoyal7/credit-card-customers) on Kaggle. \n",
    "\n",
    "The author of the dataset gives an important note: if our model predicts non-churning customers as churning, it won't hurt the business. However, we do not want to make the opposite error of predicting churning customers as non-churning. So, we should allow our model to be *sensitive* at the price of being less precise. Thus we will measure the effectiveness of our model by measuring its **Recall**: \n",
    "$$ \\mathrm{Recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$$ \n",
    "where $\\mathrm{TP}$ and $\\mathrm{FN}$ denote the number of *true positives* and *false negatives* our model predicts on the validation set, assuming that \"churning\" is our positive class.  \n",
    "\n",
    "The author was able to build a model that achieved 62% recall. The task is to build a model which improves this number. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Loading\n",
    "\n",
    "The previous owner of the data makes a note that we should ignore or delete the last two columns of the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0              39  ...                       1                      3   \n",
       "1              44  ...                       1                      2   \n",
       "2              36  ...                       1                      0   \n",
       "3              34  ...                       4                      1   \n",
       "4              21  ...                       1                      0   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0       12691.0                  777          11914.0                 1.335   \n",
       "1        8256.0                  864           7392.0                 1.541   \n",
       "2        3418.0                    0           3418.0                 2.594   \n",
       "3        3313.0                 2517            796.0                 1.405   \n",
       "4        4716.0                    0           4716.0                 2.175   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1144              42                1.625                  0.061  \n",
       "1             1291              33                3.714                  0.105  \n",
       "2             1887              20                2.333                  0.000  \n",
       "3             1171              20                2.333                  0.760  \n",
       "4              816              28                2.500                  0.000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CLIENTNUM</th>\n      <th>Attrition_Flag</th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>...</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>768805383</td>\n      <td>Existing Customer</td>\n      <td>45</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>12691.0</td>\n      <td>777</td>\n      <td>11914.0</td>\n      <td>1.335</td>\n      <td>1144</td>\n      <td>42</td>\n      <td>1.625</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>818770008</td>\n      <td>Existing Customer</td>\n      <td>49</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>44</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8256.0</td>\n      <td>864</td>\n      <td>7392.0</td>\n      <td>1.541</td>\n      <td>1291</td>\n      <td>33</td>\n      <td>3.714</td>\n      <td>0.105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>713982108</td>\n      <td>Existing Customer</td>\n      <td>51</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>2.594</td>\n      <td>1887</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>769911858</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>F</td>\n      <td>4</td>\n      <td>High School</td>\n      <td>Unknown</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3313.0</td>\n      <td>2517</td>\n      <td>796.0</td>\n      <td>1.405</td>\n      <td>1171</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>709106358</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>21</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>2.175</td>\n      <td>816</td>\n      <td>28</td>\n      <td>2.500</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df = pd.read_csv('BankChurners.csv').iloc[:,:-2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10127 entries, 0 to 10126\nData columns (total 21 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   CLIENTNUM                 10127 non-null  int64  \n 1   Attrition_Flag            10127 non-null  object \n 2   Customer_Age              10127 non-null  int64  \n 3   Gender                    10127 non-null  object \n 4   Dependent_count           10127 non-null  int64  \n 5   Education_Level           10127 non-null  object \n 6   Marital_Status            10127 non-null  object \n 7   Income_Category           10127 non-null  object \n 8   Card_Category             10127 non-null  object \n 9   Months_on_book            10127 non-null  int64  \n 10  Total_Relationship_Count  10127 non-null  int64  \n 11  Months_Inactive_12_mon    10127 non-null  int64  \n 12  Contacts_Count_12_mon     10127 non-null  int64  \n 13  Credit_Limit              10127 non-null  float64\n 14  Total_Revolving_Bal       10127 non-null  int64  \n 15  Avg_Open_To_Buy           10127 non-null  float64\n 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n 17  Total_Trans_Amt           10127 non-null  int64  \n 18  Total_Trans_Ct            10127 non-null  int64  \n 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n 20  Avg_Utilization_Ratio     10127 non-null  float64\ndtypes: float64(5), int64(10), object(6)\nmemory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CLIENTNUM                   0\n",
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "### Feature Descriptions\n",
    "\n",
    "The `CLIENTNUM` column can probably be ignored since we can identify customers based on their row in the dataframe. The `Attrition_Flag` column provides the labels we will use for our supervised-learning task. There are 19 other columns which we are free to use as training data. \n",
    "\n",
    "* `Customer_Age`: Demographic variable - Customer's Age in Years.\n",
    "* `Gender`: Demographic variable - M=Male, F=Female.\n",
    "* `Dependent_count`: Demographic variable - Number of dependents\n",
    "* `Education_Level`: Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n",
    "* `Marital_Status`: Demographic variable - Married, Single, Divorced, Unknown.\n",
    "* `Income_Category`: Demographic variable - Annual Income Category of the account holder (< \\$40K, \\$40K - 60K, \\$60K - \\$80K, \\$80K-\\$120K, > \\$120k)\n",
    "* `Card_Category`: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n",
    "* `Months_on_book`: Period of relationship with bank.\n",
    "* `Total_Relationship_Count`: Total number of products held by the customer.\n",
    "* `Months_Inactive_12_mon`: Number of months inactive in the last 12 months.\n",
    "* `Contacts_Counts_12_mon`: Number of contacts in the last 12 months.\n",
    "* `Credit_Limit`: Credit limit on the credit card.\n",
    "* `Total_Revolving_Bal`: Total revolving balance on the credit card (the portion of credit card spending that goes unpaid at the end of a billing cycle).\n",
    "* `Avg_Open_To_Buy`: Open to buy credit line (Average of last 12 months). The difference between the credit limit assigned to a cardholder account and the present balance on the account.\n",
    "* `Total_Amt_Chng_Q4_Q1`: Change in transaction amount (Q4 over Q1).\n",
    "* `Total_Trans_Amt`: Total transaction amount (last 12 months).\n",
    "* `Total_trans_Ct`: Number of transactions (last 12 months).\n",
    "* `Total_Ct_Chng_Q4_Q1`: Change in transaction count (Q4 over Q1).\n",
    "* `Avg_Utilization_Ratio`: Average percentage of credit used with respect to the credit limit.\n",
    "\n",
    "We have 10,127 entries to work with, which should be plenty to get a good model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['CLIENTNUM'], inplace=True)\n",
    "\n",
    "# 'Attrited Customer' is the positive class\n",
    "df['Attrition_Flag'].replace({'Existing Customer' : 0, 'Attrited Customer' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.83934\n",
       "1    0.16066\n",
       "Name: Attrition_Flag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Customer churn is ~16%. \n",
    "df['Attrition_Flag'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "0             54      F                1         Unknown         Single   \n",
       "1             58      F                4     High School        Married   \n",
       "2             45      F                4         Unknown         Single   \n",
       "3             34      F                2        Graduate         Single   \n",
       "4             49      F                2     High School        Married   \n",
       "5             60      F                0       Doctorate        Married   \n",
       "6             43      F                4         Unknown         Single   \n",
       "7             52      F                2         Unknown         Single   \n",
       "8             30      M                0        Graduate        Married   \n",
       "9             33      F                3        Graduate         Single   \n",
       "10            29      M                0   Post-Graduate       Divorced   \n",
       "11            57      M                2      Uneducated        Unknown   \n",
       "12            28      F                0        Graduate        Married   \n",
       "13            38      M                2         Unknown         Single   \n",
       "14            49      F                5     High School        Married   \n",
       "15            44      F                3        Graduate        Married   \n",
       "16            38      M                2         Unknown        Married   \n",
       "17            32      M                3         Unknown         Single   \n",
       "18            44      M                4   Post-Graduate         Single   \n",
       "19            46      F                1         College        Unknown   \n",
       "\n",
       "   Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "0          Unknown          Blue              36                         1   \n",
       "1          Unknown          Blue              48                         1   \n",
       "2   Less than $40K          Gold              36                         6   \n",
       "3   Less than $40K          Blue              36                         4   \n",
       "4      $40K - $60K          Blue              39                         5   \n",
       "5   Less than $40K          Blue              45                         5   \n",
       "6          Unknown          Blue              28                         2   \n",
       "7      $40K - $60K          Blue              45                         3   \n",
       "8   Less than $40K          Blue              36                         3   \n",
       "9   Less than $40K          Blue              36                         5   \n",
       "10     $60K - $80K          Blue              15                         2   \n",
       "11    $80K - $120K          Blue              36                         5   \n",
       "12         Unknown          Blue              15                         2   \n",
       "13     $60K - $80K          Blue              36                         3   \n",
       "14         Unknown        Silver              36                         6   \n",
       "15  Less than $40K          Blue              40                         6   \n",
       "16         $120K +          Blue              36                         6   \n",
       "17         $120K +          Blue              20                         6   \n",
       "18         $120K +          Blue              32                         2   \n",
       "19         Unknown          Blue              35                         5   \n",
       "\n",
       "    Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                        3                      3        3723.0   \n",
       "1                        4                      3        5396.0   \n",
       "2                        1                      3       15987.0   \n",
       "3                        3                      4        3625.0   \n",
       "4                        3                      4        2720.0   \n",
       "5                        2                      4        1438.3   \n",
       "6                        2                      1        2838.0   \n",
       "7                        1                      3        3476.0   \n",
       "8                        3                      2        2550.0   \n",
       "9                        2                      3        1457.0   \n",
       "10                       1                      3        8022.0   \n",
       "11                       3                      3        4316.0   \n",
       "12                       2                      2       23103.0   \n",
       "13                       3                      3        6692.0   \n",
       "14                       2                      2       34516.0   \n",
       "15                       2                      2        2232.0   \n",
       "16                       2                      3        3782.0   \n",
       "17                       2                      2       14244.0   \n",
       "18                       4                      2       23957.0   \n",
       "19                       3                      3        2197.0   \n",
       "\n",
       "    Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0                  1728           1995.0                 0.595   \n",
       "1                  1803           3593.0                 0.493   \n",
       "2                  1648          14339.0                 0.732   \n",
       "3                  2517           1108.0                 1.158   \n",
       "4                  1926            794.0                 0.602   \n",
       "5                   648            790.3                 0.477   \n",
       "6                  1934            904.0                 0.873   \n",
       "7                  1560           1916.0                 0.894   \n",
       "8                  1623            927.0                 0.650   \n",
       "9                     0           1457.0                 0.677   \n",
       "10                    0           8022.0                 0.381   \n",
       "11                    0           4316.0                 0.363   \n",
       "12                  897          22206.0                 0.913   \n",
       "13                 2037           4655.0                 0.401   \n",
       "14                 2019          32497.0                 0.614   \n",
       "15                 2002            230.0                 1.107   \n",
       "16                    0           3782.0                 0.717   \n",
       "17                 1673          12571.0                 0.699   \n",
       "18                 2102          21855.0                 0.997   \n",
       "19                  461           1736.0                 0.636   \n",
       "\n",
       "    Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0              8554              99                0.678   \n",
       "1              2107              39                0.393   \n",
       "2              1436              36                1.250   \n",
       "3              2616              46                1.300   \n",
       "4              3806              61                0.794   \n",
       "5              1267              27                1.077   \n",
       "6              8644              87                0.554   \n",
       "7              3496              58                0.871   \n",
       "8              1870              51                0.275   \n",
       "9              2200              45                0.364   \n",
       "10             5660              59                0.735   \n",
       "11             1920              53                0.472   \n",
       "12            14049             120                0.714   \n",
       "13             1468              36                0.241   \n",
       "14             3820              72                0.532   \n",
       "15             3803              68                0.511   \n",
       "16            14977             117                0.721   \n",
       "17             2729              66                0.535   \n",
       "18             1276              26                0.733   \n",
       "19             1955              42                0.448   \n",
       "\n",
       "    Avg_Utilization_Ratio  \n",
       "0                   0.464  \n",
       "1                   0.334  \n",
       "2                   0.103  \n",
       "3                   0.694  \n",
       "4                   0.708  \n",
       "5                   0.451  \n",
       "6                   0.681  \n",
       "7                   0.449  \n",
       "8                   0.636  \n",
       "9                   0.000  \n",
       "10                  0.000  \n",
       "11                  0.000  \n",
       "12                  0.039  \n",
       "13                  0.304  \n",
       "14                  0.058  \n",
       "15                  0.897  \n",
       "16                  0.000  \n",
       "17                  0.117  \n",
       "18                  0.088  \n",
       "19                  0.210  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54</td>\n      <td>F</td>\n      <td>1</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3723.0</td>\n      <td>1728</td>\n      <td>1995.0</td>\n      <td>0.595</td>\n      <td>8554</td>\n      <td>99</td>\n      <td>0.678</td>\n      <td>0.464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58</td>\n      <td>F</td>\n      <td>4</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>48</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5396.0</td>\n      <td>1803</td>\n      <td>3593.0</td>\n      <td>0.493</td>\n      <td>2107</td>\n      <td>39</td>\n      <td>0.393</td>\n      <td>0.334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Gold</td>\n      <td>36</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15987.0</td>\n      <td>1648</td>\n      <td>14339.0</td>\n      <td>0.732</td>\n      <td>1436</td>\n      <td>36</td>\n      <td>1.250</td>\n      <td>0.103</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3625.0</td>\n      <td>2517</td>\n      <td>1108.0</td>\n      <td>1.158</td>\n      <td>2616</td>\n      <td>46</td>\n      <td>1.300</td>\n      <td>0.694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49</td>\n      <td>F</td>\n      <td>2</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2720.0</td>\n      <td>1926</td>\n      <td>794.0</td>\n      <td>0.602</td>\n      <td>3806</td>\n      <td>61</td>\n      <td>0.794</td>\n      <td>0.708</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>60</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>45</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1438.3</td>\n      <td>648</td>\n      <td>790.3</td>\n      <td>0.477</td>\n      <td>1267</td>\n      <td>27</td>\n      <td>1.077</td>\n      <td>0.451</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>43</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>28</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2838.0</td>\n      <td>1934</td>\n      <td>904.0</td>\n      <td>0.873</td>\n      <td>8644</td>\n      <td>87</td>\n      <td>0.554</td>\n      <td>0.681</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>52</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>45</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3476.0</td>\n      <td>1560</td>\n      <td>1916.0</td>\n      <td>0.894</td>\n      <td>3496</td>\n      <td>58</td>\n      <td>0.871</td>\n      <td>0.449</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>30</td>\n      <td>M</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2550.0</td>\n      <td>1623</td>\n      <td>927.0</td>\n      <td>0.650</td>\n      <td>1870</td>\n      <td>51</td>\n      <td>0.275</td>\n      <td>0.636</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33</td>\n      <td>F</td>\n      <td>3</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1457.0</td>\n      <td>0</td>\n      <td>1457.0</td>\n      <td>0.677</td>\n      <td>2200</td>\n      <td>45</td>\n      <td>0.364</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>29</td>\n      <td>M</td>\n      <td>0</td>\n      <td>Post-Graduate</td>\n      <td>Divorced</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>15</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8022.0</td>\n      <td>0</td>\n      <td>8022.0</td>\n      <td>0.381</td>\n      <td>5660</td>\n      <td>59</td>\n      <td>0.735</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>57</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Uneducated</td>\n      <td>Unknown</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4316.0</td>\n      <td>0</td>\n      <td>4316.0</td>\n      <td>0.363</td>\n      <td>1920</td>\n      <td>53</td>\n      <td>0.472</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>28</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>15</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>23103.0</td>\n      <td>897</td>\n      <td>22206.0</td>\n      <td>0.913</td>\n      <td>14049</td>\n      <td>120</td>\n      <td>0.714</td>\n      <td>0.039</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>38</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6692.0</td>\n      <td>2037</td>\n      <td>4655.0</td>\n      <td>0.401</td>\n      <td>1468</td>\n      <td>36</td>\n      <td>0.241</td>\n      <td>0.304</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>49</td>\n      <td>F</td>\n      <td>5</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Silver</td>\n      <td>36</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34516.0</td>\n      <td>2019</td>\n      <td>32497.0</td>\n      <td>0.614</td>\n      <td>3820</td>\n      <td>72</td>\n      <td>0.532</td>\n      <td>0.058</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>44</td>\n      <td>F</td>\n      <td>3</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>40</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2232.0</td>\n      <td>2002</td>\n      <td>230.0</td>\n      <td>1.107</td>\n      <td>3803</td>\n      <td>68</td>\n      <td>0.511</td>\n      <td>0.897</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>38</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Unknown</td>\n      <td>Married</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>6</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3782.0</td>\n      <td>0</td>\n      <td>3782.0</td>\n      <td>0.717</td>\n      <td>14977</td>\n      <td>117</td>\n      <td>0.721</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>32</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Unknown</td>\n      <td>Single</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>20</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>14244.0</td>\n      <td>1673</td>\n      <td>12571.0</td>\n      <td>0.699</td>\n      <td>2729</td>\n      <td>66</td>\n      <td>0.535</td>\n      <td>0.117</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>44</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Post-Graduate</td>\n      <td>Single</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>32</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>23957.0</td>\n      <td>2102</td>\n      <td>21855.0</td>\n      <td>0.997</td>\n      <td>1276</td>\n      <td>26</td>\n      <td>0.733</td>\n      <td>0.088</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>46</td>\n      <td>F</td>\n      <td>1</td>\n      <td>College</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>35</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2197.0</td>\n      <td>461</td>\n      <td>1736.0</td>\n      <td>0.636</td>\n      <td>1955</td>\n      <td>42</td>\n      <td>0.448</td>\n      <td>0.210</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Split data into training and testing sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_y = train_df['Attrition_Flag']\n",
    "test_y = test_df['Attrition_Flag']\n",
    "\n",
    "train_X = train_df.drop(columns=['Attrition_Flag'])\n",
    "test_X = test_df.drop(columns=['Attrition_Flag'])\n",
    "\n",
    "train_X.iloc[0:20, :]"
   ]
  },
  {
   "source": [
    "## Encoding categorical variables\n",
    "\n",
    "Our data enjoys five different features whose values are represented as strings. We should encode these into numeric data before moving on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Education_Level',\n",
       " 'Marital_Status',\n",
       " 'Income_Category',\n",
       " 'Card_Category']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from pandas.api.types import is_object_dtype\n",
    "\n",
    "obj_cols = [c for c in train_X.columns if is_object_dtype(train_X[c])]\n",
    "obj_cols"
   ]
  },
  {
   "source": [
    "### Gender\n",
    "\n",
    "Unfortunately, the data only has two gender values. It is possible that customers of non-binary gender have significantly different attrition rates, but instead we will have to work within the very coarse framework given to us.\n",
    "\n",
    "We will encode this as a binary variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.528206\n",
       "1    0.471794\n",
       "Name: Gender, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "train_X['Gender'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Education Level\n",
    "\n",
    "The values are partially-ordered since education levels follow a linear path, except that we have an `'Unknown'` value. We do not know why certain entries are labeled this way. We will assume it's because the customers chose not to provide this information, in which case this may be a useful category to keep. In any case, ~15% of entries are labeled `'Unknown'`, so we should not get rid of them.\n",
    "\n",
    "We will use integer encoding with the assignment that `'Unknown'` is `0`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4    0.312060\n",
       "2    0.199852\n",
       "0    0.148747\n",
       "1    0.144550\n",
       "3    0.100728\n",
       "5    0.050241\n",
       "6    0.043822\n",
       "Name: Education_Level, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "train_X['Education_Level'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Marital Status\n",
    "\n",
    "There is no linear ordering on these values. We will use one hot encoding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Married     0.465004\n",
       "Single      0.388100\n",
       "Divorced    0.075423\n",
       "Unknown     0.071473\n",
       "Name: Marital_Status, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "train_X['Marital_Status'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Income Category\n",
    "\n",
    "We can see our data is partially ordered with an `'Unknown'` value. Let's encode it in a similar way to how we encoded Education Level."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Less than $40K    0.347118\n",
       "$40K - $60K       0.179361\n",
       "$80K - $120K      0.152697\n",
       "$60K - $80K       0.138501\n",
       "Unknown           0.109740\n",
       "$120K +           0.072584\n",
       "Name: Income_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "train_X['Income_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "### Card Category\n",
    "\n",
    "I will make the assumption that the card categories are ordered such that \n",
    "$$ \\textrm{Blue} < \\textrm{Silver} < \\textrm{Gold} < \\textrm{Platinum}.$$\n",
    "The value counts for this feature gives evidence for this ordering."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Blue        0.932848\n",
       "Silver      0.053821\n",
       "Gold        0.011480\n",
       "Platinum    0.001852\n",
       "Name: Card_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "train_X['Card_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "### Summary\n",
    "\n",
    "We will bundle these encodings together into one column-transformer which we will later use in a pipeline. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "# TODO: Fix 'Unknown' values.\n",
    "\n",
    "encoder = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), \n",
    "        ['Gender', 'Marital_Status']),\n",
    "    (OrdinalEncoder(categories=[\n",
    "            ['Unknown', 'Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'],\n",
    "            ['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'],\n",
    "            ['Blue', 'Silver', 'Gold', 'Platinum']]), \n",
    "        ['Education_Level', 'Income_Category', 'Card_Category']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "source": [
    "## Dealing With Missing Data\n",
    "\n",
    "Recall that our `'Education_Level'` and `'Income_Category'` features contained a good amount of missing data. We will assume that this is not completely random; it may be the case that the customers willingly refused to provide this information to us. In this case, the missing data may be considered as data itself. \n",
    "\n",
    "We must make a choice for how to deal with this missing data. It would be nice if, at this step, we could fill in missing data intelligently without deleting any information. We may consider deleting features at a later step during feature selection.\n",
    "\n",
    "First, we will create two new features `'Gave_Education'` and `'Gave_Income'` which has value `'False'` if the corresponding value of `'Education_Level'` and `'Income_Category' is `'Unknown'`, and `'True'` otherwise.\n",
    "\n",
    "After this, we will train a machine learning algorithm on the data without missing values to predict what the missing values might be."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Baseline Model\n",
    "\n",
    "Let's quickly train a logistic regression model to get a good baseline before we start using dimensionality reduction techniques. This way, we will be able to run sanity checks and see if our tehcniques are working towards improving the model or not."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "logreg.fit(train_X, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4453846153846154"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(logreg, train_X, train_y, scoring='recall').mean()"
   ]
  },
  {
   "source": [
    "## Feature Selection\n",
    "\n",
    "Here, we will attempt to apply some dimensionality reduction techniques, with a focus on maintaining the explainability of our future model. At the core, our task is to solve a binary classification problem using a mix of categorical and numerical data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "We will compare each of our features to our target variable. If the feature is of integer type, we will apply the $\\chi^2$ test. For features of float type, we will perform an Analysis of Variance (ANOVA)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Customer_Age',\n",
       " 'Gender',\n",
       " 'Dependent_count',\n",
       " 'Education_Level',\n",
       " 'Income_Category',\n",
       " 'Card_Category',\n",
       " 'Months_on_book',\n",
       " 'Total_Relationship_Count',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Contacts_Count_12_mon',\n",
       " 'Total_Revolving_Bal',\n",
       " 'Total_Trans_Amt',\n",
       " 'Total_Trans_Ct',\n",
       " 'Divorced',\n",
       " 'Married',\n",
       " 'Single']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from pandas.api.types import is_integer_dtype\n",
    "\n",
    "int_cols = []\n",
    "num_cols = \n",
    "\n",
    "int_cols = [c for c in train_X.columns if is_integer_dtype(train_X[c])]\n",
    "int_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p-value Statistics:\n\nCustomer_Age: 0.00018754729896914405\nFeature is probably independent of target: False\n\nGender: 0.0019387268628536134\nFeature is probably independent of target: False\n\nDependent_count: 0.11853926182350483\nFeature is probably independent of target: True\n\nEducation_Level: 0.13604314302570286\nFeature is probably independent of target: True\n\nIncome_Category: 0.033668678227946586\nFeature is probably independent of target: False\n\nCard_Category: 0.9969557126182217\nFeature is probably independent of target: True\n\nMonths_on_book: 0.0072873588005836374\nFeature is probably independent of target: False\n\nTotal_Relationship_Count: 3.756870908123146e-27\nFeature is probably independent of target: False\n\nMonths_Inactive_12_mon: 1.0826609625096649e-20\nFeature is probably independent of target: False\n\nContacts_Count_12_mon: 8.622028303171061e-41\nFeature is probably independent of target: False\n\nTotal_Revolving_Bal: 0.0\nFeature is probably independent of target: False\n\nTotal_Trans_Amt: 0.0\nFeature is probably independent of target: False\n\nTotal_Trans_Ct: 0.0\nFeature is probably independent of target: False\n\nDivorced: 0.5853203390581991\nFeature is probably independent of target: True\n\nMarried: 0.23936404094514024\nFeature is probably independent of target: True\n\nSingle: 0.34414046037950574\nFeature is probably independent of target: True\n\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_values = chi2(train_X[int_cols], train_y)[1]\n",
    "col_filter = {}\n",
    "\n",
    "print('p-value Statistics:\\n')\n",
    "for i in range(len(int_cols)):\n",
    "    feature = int_cols[i]\n",
    "    p = p_values[i]\n",
    "\n",
    "    print(f'{feature}: {p}')\n",
    "\n",
    "    is_independent = False if p <= alpha else True\n",
    "    col_filter[feature] = not is_independent    # Will throw away features which are independent from the target.\n",
    "\n",
    "    print(f'Feature is probably independent of target: {is_independent}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}