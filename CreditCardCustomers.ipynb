{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Credit Card Customers\n",
    "\n",
    "In this project, we will use data from a credit card company to build a binary classifier which predicts which customers will churn. The data can be obtained from [this dataset](https://www.kaggle.com/sakshigoyal7/credit-card-customers) on Kaggle. \n",
    "\n",
    "The author of the dataset gives an important note: if our model predicts non-churning customers as churning, it won't hurt the business. However, we do not want to make the opposite error of predicting churning customers as non-churning. So, we should allow our model to be *sensitive* at the price of being less precise. Thus we will measure the effectiveness of our model by measuring its **Recall**: \n",
    "$$ \\mathrm{Recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$$ \n",
    "where $\\mathrm{TP}$ and $\\mathrm{FN}$ denote the number of *true positives* and *false negatives* our model predicts on the validation set, assuming that \"churning\" is our positive class.  \n",
    "\n",
    "The author was able to build a model that achieved 62% recall. The task is to build a model which improves this number. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Loading\n",
    "\n",
    "The previous owner of the data makes a note that we should ignore or delete the last two columns of the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0              39  ...                       1                      3   \n",
       "1              44  ...                       1                      2   \n",
       "2              36  ...                       1                      0   \n",
       "3              34  ...                       4                      1   \n",
       "4              21  ...                       1                      0   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0       12691.0                  777          11914.0                 1.335   \n",
       "1        8256.0                  864           7392.0                 1.541   \n",
       "2        3418.0                    0           3418.0                 2.594   \n",
       "3        3313.0                 2517            796.0                 1.405   \n",
       "4        4716.0                    0           4716.0                 2.175   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1144              42                1.625                  0.061  \n",
       "1             1291              33                3.714                  0.105  \n",
       "2             1887              20                2.333                  0.000  \n",
       "3             1171              20                2.333                  0.760  \n",
       "4              816              28                2.500                  0.000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CLIENTNUM</th>\n      <th>Attrition_Flag</th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>...</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>768805383</td>\n      <td>Existing Customer</td>\n      <td>45</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>12691.0</td>\n      <td>777</td>\n      <td>11914.0</td>\n      <td>1.335</td>\n      <td>1144</td>\n      <td>42</td>\n      <td>1.625</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>818770008</td>\n      <td>Existing Customer</td>\n      <td>49</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>44</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8256.0</td>\n      <td>864</td>\n      <td>7392.0</td>\n      <td>1.541</td>\n      <td>1291</td>\n      <td>33</td>\n      <td>3.714</td>\n      <td>0.105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>713982108</td>\n      <td>Existing Customer</td>\n      <td>51</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>0</td>\n      <td>3418.0</td>\n      <td>2.594</td>\n      <td>1887</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>769911858</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>F</td>\n      <td>4</td>\n      <td>High School</td>\n      <td>Unknown</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3313.0</td>\n      <td>2517</td>\n      <td>796.0</td>\n      <td>1.405</td>\n      <td>1171</td>\n      <td>20</td>\n      <td>2.333</td>\n      <td>0.760</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>709106358</td>\n      <td>Existing Customer</td>\n      <td>40</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>21</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>0</td>\n      <td>4716.0</td>\n      <td>2.175</td>\n      <td>816</td>\n      <td>28</td>\n      <td>2.500</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('BankChurners.csv').iloc[:,:-2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10127 entries, 0 to 10126\nData columns (total 21 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   CLIENTNUM                 10127 non-null  int64  \n 1   Attrition_Flag            10127 non-null  object \n 2   Customer_Age              10127 non-null  int64  \n 3   Gender                    10127 non-null  object \n 4   Dependent_count           10127 non-null  int64  \n 5   Education_Level           10127 non-null  object \n 6   Marital_Status            10127 non-null  object \n 7   Income_Category           10127 non-null  object \n 8   Card_Category             10127 non-null  object \n 9   Months_on_book            10127 non-null  int64  \n 10  Total_Relationship_Count  10127 non-null  int64  \n 11  Months_Inactive_12_mon    10127 non-null  int64  \n 12  Contacts_Count_12_mon     10127 non-null  int64  \n 13  Credit_Limit              10127 non-null  float64\n 14  Total_Revolving_Bal       10127 non-null  int64  \n 15  Avg_Open_To_Buy           10127 non-null  float64\n 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n 17  Total_Trans_Amt           10127 non-null  int64  \n 18  Total_Trans_Ct            10127 non-null  int64  \n 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n 20  Avg_Utilization_Ratio     10127 non-null  float64\ndtypes: float64(5), int64(10), object(6)\nmemory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CLIENTNUM                   0\n",
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "It appears that there is no null data, but further inspection shows that the null data has been changed to the string `'Unknown'`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CLIENTNUM                      0\n",
       "Attrition_Flag                 0\n",
       "Customer_Age                   0\n",
       "Gender                         0\n",
       "Dependent_count                0\n",
       "Education_Level             1519\n",
       "Marital_Status               749\n",
       "Income_Category             1112\n",
       "Card_Category                  0\n",
       "Months_on_book                 0\n",
       "Total_Relationship_Count       0\n",
       "Months_Inactive_12_mon         0\n",
       "Contacts_Count_12_mon          0\n",
       "Credit_Limit                   0\n",
       "Total_Revolving_Bal            0\n",
       "Avg_Open_To_Buy                0\n",
       "Total_Amt_Chng_Q4_Q1           0\n",
       "Total_Trans_Amt                0\n",
       "Total_Trans_Ct                 0\n",
       "Total_Ct_Chng_Q4_Q1            0\n",
       "Avg_Utilization_Ratio          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "unknown = df == 'Unknown'\n",
    "unknown.sum()"
   ]
  },
  {
   "source": [
    "### Feature Descriptions\n",
    "\n",
    "The `CLIENTNUM` column can probably be ignored since we can identify customers based on their row in the dataframe. The `Attrition_Flag` column provides the labels we will use for our supervised-learning task. There are 19 other columns which we are free to use as training data. \n",
    "\n",
    "* `Customer_Age`: Demographic variable - Customer's Age in Years.\n",
    "* `Gender`: Demographic variable - M=Male, F=Female.\n",
    "* `Dependent_count`: Demographic variable - Number of dependents\n",
    "* `Education_Level`: Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n",
    "* `Marital_Status`: Demographic variable - Married, Single, Divorced, Unknown.\n",
    "* `Income_Category`: Demographic variable - Annual Income Category of the account holder (< \\$40K, \\$40K - 60K, \\$60K - \\$80K, \\$80K-\\$120K, > \\$120k)\n",
    "* `Card_Category`: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n",
    "* `Months_on_book`: Period of relationship with bank.\n",
    "* `Total_Relationship_Count`: Total number of products held by the customer.\n",
    "* `Months_Inactive_12_mon`: Number of months inactive in the last 12 months.\n",
    "* `Contacts_Counts_12_mon`: Number of contacts in the last 12 months.\n",
    "* `Credit_Limit`: Credit limit on the credit card.\n",
    "* `Total_Revolving_Bal`: Total revolving balance on the credit card (the portion of credit card spending that goes unpaid at the end of a billing cycle).\n",
    "* `Avg_Open_To_Buy`: Open to buy credit line (Average of last 12 months). The difference between the credit limit assigned to a cardholder account and the present balance on the account.\n",
    "* `Total_Amt_Chng_Q4_Q1`: Change in transaction amount (Q4 over Q1).\n",
    "* `Total_Trans_Amt`: Total transaction amount (last 12 months).\n",
    "* `Total_trans_Ct`: Number of transactions (last 12 months).\n",
    "* `Total_Ct_Chng_Q4_Q1`: Change in transaction count (Q4 over Q1).\n",
    "* `Avg_Utilization_Ratio`: Average percentage of credit used with respect to the credit limit.\n",
    "\n",
    "We have 10,127 entries to work with, which should be plenty to get a good model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['CLIENTNUM'], inplace=True)\n",
    "\n",
    "# 'Attrited Customer' is the positive class\n",
    "df['Attrition_Flag'].replace({'Existing Customer' : 0, 'Attrited Customer' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.83934\n",
       "1    0.16066\n",
       "Name: Attrition_Flag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Customer churn is ~16%. \n",
    "df['Attrition_Flag'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "0             56      M                3         College        Married   \n",
       "1             42      F                2        Graduate        Unknown   \n",
       "2             46      M                3     High School        Married   \n",
       "3             50      F                3      Uneducated         Single   \n",
       "4             51      M                1      Uneducated        Married   \n",
       "5             64      F                0      Uneducated        Married   \n",
       "6             53      F                5        Graduate         Single   \n",
       "7             55      M                2         College        Married   \n",
       "8             37      M                2       Doctorate         Single   \n",
       "9             41      F                1     High School         Single   \n",
       "10            44      M                3     High School         Single   \n",
       "11            38      F                2      Uneducated        Married   \n",
       "12            44      M                4      Uneducated        Married   \n",
       "13            51      M                1       Doctorate        Married   \n",
       "14            45      M                4        Graduate         Single   \n",
       "15            58      F                4        Graduate        Married   \n",
       "16            34      M                2     High School         Single   \n",
       "17            62      F                0       Doctorate        Married   \n",
       "18            48      M                2        Graduate        Unknown   \n",
       "19            34      F                2        Graduate        Unknown   \n",
       "\n",
       "   Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "0          $120K +          Blue              43                         6   \n",
       "1          Unknown          Blue              34                         5   \n",
       "2     $80K - $120K          Blue              27                         4   \n",
       "3          Unknown          Blue              36                         2   \n",
       "4      $60K - $80K          Blue              38                         3   \n",
       "5          Unknown          Blue              54                         6   \n",
       "6      $40K - $60K          Blue              41                         2   \n",
       "7          $120K +          Blue              37                         5   \n",
       "8          $120K +          Blue              32                         3   \n",
       "9   Less than $40K          Blue              31                         4   \n",
       "10     $40K - $60K          Blue              34                         5   \n",
       "11  Less than $40K          Blue              36                         2   \n",
       "12    $80K - $120K        Silver              27                         4   \n",
       "13    $80K - $120K          Blue              44                         5   \n",
       "14    $80K - $120K          Blue              36                         6   \n",
       "15         Unknown          Blue              42                         3   \n",
       "16         Unknown          Blue              36                         3   \n",
       "17     $40K - $60K          Blue              51                         3   \n",
       "18     $40K - $60K          Blue              36                         5   \n",
       "19         Unknown        Silver              16                         2   \n",
       "\n",
       "    Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                        2                      2       17539.0   \n",
       "1                        2                      2       19373.0   \n",
       "2                        2                      3        4964.0   \n",
       "3                        3                      3        3187.0   \n",
       "4                        3                      1       13731.0   \n",
       "5                        1                      2        3250.0   \n",
       "6                        1                      3        9815.0   \n",
       "7                        2                      3       32641.0   \n",
       "8                        3                      5       32056.0   \n",
       "9                        2                      1        1998.0   \n",
       "10                       3                      1        8997.0   \n",
       "11                       3                      2        7825.0   \n",
       "12                       3                      2       34516.0   \n",
       "13                       2                      4        8031.0   \n",
       "14                       3                      1        8063.0   \n",
       "15                       3                      4       10247.0   \n",
       "16                       4                      2       22886.0   \n",
       "17                       3                      2        3377.0   \n",
       "18                       1                      2       13068.0   \n",
       "19                       2                      1       32292.0   \n",
       "\n",
       "    Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0                  2517          15022.0                 0.743   \n",
       "1                  1142          18231.0                 0.655   \n",
       "2                  2316           2648.0                 0.793   \n",
       "3                   986           2201.0                 0.615   \n",
       "4                  1375          12356.0                 0.878   \n",
       "5                  1992           1258.0                 0.715   \n",
       "6                  1699           8116.0                 0.620   \n",
       "7                  1551          31090.0                 0.488   \n",
       "8                  1887          30169.0                 0.831   \n",
       "9                     0           1998.0                 0.717   \n",
       "10                  708           8289.0                 0.586   \n",
       "11                    0           7825.0                 0.724   \n",
       "12                 1043          33473.0                 0.690   \n",
       "13                 1167           6864.0                 0.549   \n",
       "14                 1485           6578.0                 0.872   \n",
       "15                 1600           8647.0                 0.630   \n",
       "16                  836          22050.0                 0.889   \n",
       "17                  948           2429.0                 0.461   \n",
       "18                 1718          11350.0                 0.607   \n",
       "19                 1731          30561.0                 0.751   \n",
       "\n",
       "    Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0              1220              30                0.765   \n",
       "1              1792              48                0.455   \n",
       "2              3279              66                0.941   \n",
       "3              2381              47                0.516   \n",
       "4             14826              99                0.707   \n",
       "5              1355              36                0.565   \n",
       "6              7962              89                0.561   \n",
       "7              1327              30                0.304   \n",
       "8              2730              68                0.700   \n",
       "9              4637              68                0.889   \n",
       "10             4558              62                0.676   \n",
       "11            14326             100                0.786   \n",
       "12             4654              59                0.639   \n",
       "13             3576              77                0.791   \n",
       "14             4275              77                0.833   \n",
       "15             1754              44                0.692   \n",
       "16             2652              61                0.743   \n",
       "17             1407              44                0.467   \n",
       "18              937              28                0.556   \n",
       "19             7564              76                0.810   \n",
       "\n",
       "    Avg_Utilization_Ratio  \n",
       "0                   0.144  \n",
       "1                   0.059  \n",
       "2                   0.467  \n",
       "3                   0.309  \n",
       "4                   0.100  \n",
       "5                   0.613  \n",
       "6                   0.173  \n",
       "7                   0.048  \n",
       "8                   0.059  \n",
       "9                   0.000  \n",
       "10                  0.079  \n",
       "11                  0.000  \n",
       "12                  0.030  \n",
       "13                  0.145  \n",
       "14                  0.184  \n",
       "15                  0.156  \n",
       "16                  0.037  \n",
       "17                  0.281  \n",
       "18                  0.131  \n",
       "19                  0.054  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>M</td>\n      <td>3</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>43</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>17539.0</td>\n      <td>2517</td>\n      <td>15022.0</td>\n      <td>0.743</td>\n      <td>1220</td>\n      <td>30</td>\n      <td>0.765</td>\n      <td>0.144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>19373.0</td>\n      <td>1142</td>\n      <td>18231.0</td>\n      <td>0.655</td>\n      <td>1792</td>\n      <td>48</td>\n      <td>0.455</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>27</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4964.0</td>\n      <td>2316</td>\n      <td>2648.0</td>\n      <td>0.793</td>\n      <td>3279</td>\n      <td>66</td>\n      <td>0.941</td>\n      <td>0.467</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>F</td>\n      <td>3</td>\n      <td>Uneducated</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3187.0</td>\n      <td>986</td>\n      <td>2201.0</td>\n      <td>0.615</td>\n      <td>2381</td>\n      <td>47</td>\n      <td>0.516</td>\n      <td>0.309</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$60K - $80K</td>\n      <td>Blue</td>\n      <td>38</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13731.0</td>\n      <td>1375</td>\n      <td>12356.0</td>\n      <td>0.878</td>\n      <td>14826</td>\n      <td>99</td>\n      <td>0.707</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>64</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>54</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3250.0</td>\n      <td>1992</td>\n      <td>1258.0</td>\n      <td>0.715</td>\n      <td>1355</td>\n      <td>36</td>\n      <td>0.565</td>\n      <td>0.613</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>53</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9815.0</td>\n      <td>1699</td>\n      <td>8116.0</td>\n      <td>0.620</td>\n      <td>7962</td>\n      <td>89</td>\n      <td>0.561</td>\n      <td>0.173</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>55</td>\n      <td>M</td>\n      <td>2</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>37</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>32641.0</td>\n      <td>1551</td>\n      <td>31090.0</td>\n      <td>0.488</td>\n      <td>1327</td>\n      <td>30</td>\n      <td>0.304</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Doctorate</td>\n      <td>Single</td>\n      <td>$120K +</td>\n      <td>Blue</td>\n      <td>32</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>32056.0</td>\n      <td>1887</td>\n      <td>30169.0</td>\n      <td>0.831</td>\n      <td>2730</td>\n      <td>68</td>\n      <td>0.700</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>F</td>\n      <td>1</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1998.0</td>\n      <td>0</td>\n      <td>1998.0</td>\n      <td>0.717</td>\n      <td>4637</td>\n      <td>68</td>\n      <td>0.889</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8997.0</td>\n      <td>708</td>\n      <td>8289.0</td>\n      <td>0.586</td>\n      <td>4558</td>\n      <td>62</td>\n      <td>0.676</td>\n      <td>0.079</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7825.0</td>\n      <td>0</td>\n      <td>7825.0</td>\n      <td>0.724</td>\n      <td>14326</td>\n      <td>100</td>\n      <td>0.786</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Uneducated</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Silver</td>\n      <td>27</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>34516.0</td>\n      <td>1043</td>\n      <td>33473.0</td>\n      <td>0.690</td>\n      <td>4654</td>\n      <td>59</td>\n      <td>0.639</td>\n      <td>0.030</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>44</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8031.0</td>\n      <td>1167</td>\n      <td>6864.0</td>\n      <td>0.549</td>\n      <td>3576</td>\n      <td>77</td>\n      <td>0.791</td>\n      <td>0.145</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Graduate</td>\n      <td>Single</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8063.0</td>\n      <td>1485</td>\n      <td>6578.0</td>\n      <td>0.872</td>\n      <td>4275</td>\n      <td>77</td>\n      <td>0.833</td>\n      <td>0.184</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>58</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Graduate</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>42</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>10247.0</td>\n      <td>1600</td>\n      <td>8647.0</td>\n      <td>0.630</td>\n      <td>1754</td>\n      <td>44</td>\n      <td>0.692</td>\n      <td>0.156</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>34</td>\n      <td>M</td>\n      <td>2</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>Unknown</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>22886.0</td>\n      <td>836</td>\n      <td>22050.0</td>\n      <td>0.889</td>\n      <td>2652</td>\n      <td>61</td>\n      <td>0.743</td>\n      <td>0.037</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>62</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>51</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3377.0</td>\n      <td>948</td>\n      <td>2429.0</td>\n      <td>0.461</td>\n      <td>1407</td>\n      <td>44</td>\n      <td>0.467</td>\n      <td>0.281</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>48</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13068.0</td>\n      <td>1718</td>\n      <td>11350.0</td>\n      <td>0.607</td>\n      <td>937</td>\n      <td>28</td>\n      <td>0.556</td>\n      <td>0.131</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>34</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Graduate</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Silver</td>\n      <td>16</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>32292.0</td>\n      <td>1731</td>\n      <td>30561.0</td>\n      <td>0.751</td>\n      <td>7564</td>\n      <td>76</td>\n      <td>0.810</td>\n      <td>0.054</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Split data into training and testing sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=808)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_y = train_df['Attrition_Flag']\n",
    "test_y = test_df['Attrition_Flag']\n",
    "\n",
    "train_X = train_df.drop(columns=['Attrition_Flag'])\n",
    "test_X = test_df.drop(columns=['Attrition_Flag'])\n",
    "\n",
    "train_X.iloc[0:20, :]"
   ]
  },
  {
   "source": [
    "## Encoding categorical variables\n",
    "\n",
    "Our data enjoys five different features whose values are represented as strings. We should encode these into numeric data before moving on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Education_Level',\n",
       " 'Marital_Status',\n",
       " 'Income_Category',\n",
       " 'Card_Category']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from pandas.api.types import is_object_dtype\n",
    "\n",
    "obj_cols = [c for c in train_X.columns if is_object_dtype(train_X[c])]\n",
    "obj_cols"
   ]
  },
  {
   "source": [
    "### Gender\n",
    "\n",
    "Unfortunately, the data only has two gender values. It is possible that customers of non-binary gender have significantly different attrition rates, but instead we will have to work within the very coarse framework given to us.\n",
    "\n",
    "Integer encoding and one hot encoding are equivalent for a binary variable, so either one will work. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "F    0.533144\n",
       "M    0.466856\n",
       "Name: Gender, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_X['Gender'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Education Level\n",
    "\n",
    "The values are ordered since the education levels follow a linear path, except that we have an `'Unknown'` value. We do not know why certain entries are labeled this way. We will assume it's because the customers chose not to provide this information, in which case this may be a useful category to keep. We will worry about these values later.\n",
    "\n",
    "We will use integer encoding for this feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Graduate         0.309098\n",
       "High School      0.202074\n",
       "Unknown          0.148747\n",
       "Uneducated       0.143563\n",
       "College          0.098136\n",
       "Post-Graduate    0.051352\n",
       "Doctorate        0.047031\n",
       "Name: Education_Level, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_X['Education_Level'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Marital Status\n",
    "\n",
    "There is no linear ordering on these values. We will worry about ther `'Unknown'` values later.\n",
    "\n",
    "We will use one hot encoding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Married     0.463400\n",
       "Single      0.390693\n",
       "Divorced    0.073201\n",
       "Unknown     0.072707\n",
       "Name: Marital_Status, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_X['Marital_Status'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "source": [
    "### Income Category\n",
    "\n",
    "The income categories may be sensibly ordered from smallest to largest. We will worry about the `'Unknown'` values later.\n",
    "\n",
    "We will use integer encoding, from smallest to largest income. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Less than $40K    0.350697\n",
       "$40K - $60K       0.176892\n",
       "$80K - $120K      0.147513\n",
       "$60K - $80K       0.139119\n",
       "Unknown           0.114924\n",
       "$120K +           0.070855\n",
       "Name: Income_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_X['Income_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "### Card Category\n",
    "\n",
    "I will make the assumption that the card categories are ordered such that \n",
    "$$ \\textrm{Blue} < \\textrm{Silver} < \\textrm{Gold} < \\textrm{Platinum}.$$\n",
    "The value counts for this feature gives evidence for this ordering."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Blue        0.932107\n",
       "Silver      0.054685\n",
       "Gold        0.011357\n",
       "Platinum    0.001852\n",
       "Name: Card_Category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_X['Card_Category'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "### Summary\n",
    "\n",
    "We will bundle these encodings together into one column-transformer which we will later use in a pipeline. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "encoder = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), \n",
    "        ['Gender', 'Marital_Status']),\n",
    "    (OrdinalEncoder(categories=[\n",
    "            ['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'],\n",
    "            ['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'],\n",
    "            ['Blue', 'Silver', 'Gold', 'Platinum']]), \n",
    "        ['Education_Level', 'Income_Category', 'Card_Category']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "source": [
    "## Dealing With Missing Data\n",
    "\n",
    "Recall that our `'Education_Level'`, `'Marital_Status'`, and `'Income_Category'` features contained a good amount of missing data. We will assume that this is not completely random; it may be the case that the customers willingly refused to provide this information to us. In this case, the missing data may be considered as data itself. \n",
    "\n",
    "We must make a choice for how to deal with this missing data. It would be nice if, at this step, we could fill in missing data intelligently without deleting any information. We may consider deleting features at a later step during feature selection.\n",
    "\n",
    "First, we will create two new features `'Gave_Education'`, `'Gave_Marital_Status'` and `'Gave_Income'` which has value `'False'` if the corresponding feature is `'Unknown'`. Otherwise, it has value `'True'`.\n",
    "\n",
    "After this, we will train a machine learning algorithm on the data without missing values to predict what the missing values might be."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Creating New Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "8096            37      M                3     High School         Single   \n",
       "8097            44      F                2         College        Married   \n",
       "8098            33      F                4         College         Single   \n",
       "8099            50      F                4       Doctorate        Married   \n",
       "8100            65      F                0      Uneducated         Single   \n",
       "\n",
       "     Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "8096    $80K - $120K          Blue              31                         4   \n",
       "8097     $40K - $60K          Blue              39                         4   \n",
       "8098  Less than $40K          Blue              36                         1   \n",
       "8099         Unknown        Silver              36                         3   \n",
       "8100  Less than $40K          Blue              50                         3   \n",
       "\n",
       "      Months_Inactive_12_mon  ...  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "8096                       2  ...                 1006           4693.0   \n",
       "8097                       1  ...                  775            926.0   \n",
       "8098                       3  ...                    0           1438.3   \n",
       "8099                       2  ...                 2096          32420.0   \n",
       "8100                       4  ...                  377           1320.0   \n",
       "\n",
       "      Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "8096                 0.734             2835              57   \n",
       "8097                 0.847             4471              71   \n",
       "8098                 0.566             4641              85   \n",
       "8099                 0.666             7042              73   \n",
       "8100                 1.048             2799              49   \n",
       "\n",
       "      Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Gave_Education  \\\n",
       "8096                0.900                  0.177            True   \n",
       "8097                0.614                  0.456            True   \n",
       "8098                0.700                  0.000            True   \n",
       "8099                0.553                  0.061            True   \n",
       "8100                0.485                  0.222            True   \n",
       "\n",
       "      Gave_Marital_Status  Gave_Income  \n",
       "8096                 True         True  \n",
       "8097                 True         True  \n",
       "8098                 True         True  \n",
       "8099                 True        False  \n",
       "8100                 True         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Education_Level</th>\n      <th>Marital_Status</th>\n      <th>Income_Category</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>...</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n      <th>Gave_Education</th>\n      <th>Gave_Marital_Status</th>\n      <th>Gave_Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8096</th>\n      <td>37</td>\n      <td>M</td>\n      <td>3</td>\n      <td>High School</td>\n      <td>Single</td>\n      <td>$80K - $120K</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1006</td>\n      <td>4693.0</td>\n      <td>0.734</td>\n      <td>2835</td>\n      <td>57</td>\n      <td>0.900</td>\n      <td>0.177</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8097</th>\n      <td>44</td>\n      <td>F</td>\n      <td>2</td>\n      <td>College</td>\n      <td>Married</td>\n      <td>$40K - $60K</td>\n      <td>Blue</td>\n      <td>39</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>775</td>\n      <td>926.0</td>\n      <td>0.847</td>\n      <td>4471</td>\n      <td>71</td>\n      <td>0.614</td>\n      <td>0.456</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8098</th>\n      <td>33</td>\n      <td>F</td>\n      <td>4</td>\n      <td>College</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1438.3</td>\n      <td>0.566</td>\n      <td>4641</td>\n      <td>85</td>\n      <td>0.700</td>\n      <td>0.000</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8099</th>\n      <td>50</td>\n      <td>F</td>\n      <td>4</td>\n      <td>Doctorate</td>\n      <td>Married</td>\n      <td>Unknown</td>\n      <td>Silver</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2096</td>\n      <td>32420.0</td>\n      <td>0.666</td>\n      <td>7042</td>\n      <td>73</td>\n      <td>0.553</td>\n      <td>0.061</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8100</th>\n      <td>65</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Uneducated</td>\n      <td>Single</td>\n      <td>Less than $40K</td>\n      <td>Blue</td>\n      <td>50</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>377</td>\n      <td>1320.0</td>\n      <td>1.048</td>\n      <td>2799</td>\n      <td>49</td>\n      <td>0.485</td>\n      <td>0.222</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_X['Gave_Education'] = train_X['Education_Level'] != 'Unknown'\n",
    "test_X['Gave_Education'] = test_X['Education_Level'] != 'Unknown'\n",
    "\n",
    "train_X['Gave_Marital_Status'] = train_X['Marital_Status'] != 'Unknown'\n",
    "test_X['Gave_Marital_Status'] = test_X['Marital_Status'] != 'Unknown'\n",
    "\n",
    "train_X['Gave_Income'] = train_X['Income_Category'] != 'Unknown'\n",
    "test_X['Gave_Income'] = test_X['Income_Category'] != 'Unknown'\n",
    "\n",
    "train_X.tail()"
   ]
  },
  {
   "source": [
    "### Prepping Data for Imputer Model\n",
    "\n",
    "Note that we won't use the features we've just created above. They would all be constant since we are restricting to data with no missing values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows:  5658\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Attrition_Flag              0\n",
       "Customer_Age                0\n",
       "Gender                      0\n",
       "Dependent_count             0\n",
       "Education_Level             0\n",
       "Marital_Status              0\n",
       "Income_Category             0\n",
       "Card_Category               0\n",
       "Months_on_book              0\n",
       "Total_Relationship_Count    0\n",
       "Months_Inactive_12_mon      0\n",
       "Contacts_Count_12_mon       0\n",
       "Credit_Limit                0\n",
       "Total_Revolving_Bal         0\n",
       "Avg_Open_To_Buy             0\n",
       "Total_Amt_Chng_Q4_Q1        0\n",
       "Total_Trans_Amt             0\n",
       "Total_Trans_Ct              0\n",
       "Total_Ct_Chng_Q4_Q1         0\n",
       "Avg_Utilization_Ratio       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "not_missing_df = train_df[(train_df['Education_Level'] != 'Unknown') &\n",
    "                          (train_df['Marital_Status']  != 'Unknown') &\n",
    "                          (train_df['Income_Category'] != 'Unknown')  ].copy()\n",
    "\n",
    "print('Number of rows: ', len(not_missing_df))\n",
    "unknown = not_missing_df == 'Unknown'\n",
    "unknown.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Customer_Age Gender  Dependent_count Card_Category  Months_on_book  \\\n",
       "0             56      M                3          Blue              43   \n",
       "2             46      M                3          Blue              27   \n",
       "4             51      M                1          Blue              38   \n",
       "6             53      F                5          Blue              41   \n",
       "7             55      M                2          Blue              37   \n",
       "8             37      M                2          Blue              32   \n",
       "9             41      F                1          Blue              31   \n",
       "10            44      M                3          Blue              34   \n",
       "11            38      F                2          Blue              36   \n",
       "12            44      M                4        Silver              27   \n",
       "\n",
       "    Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                          6                       2                      2   \n",
       "2                          4                       2                      3   \n",
       "4                          3                       3                      1   \n",
       "6                          2                       1                      3   \n",
       "7                          5                       2                      3   \n",
       "8                          3                       3                      5   \n",
       "9                          4                       2                      1   \n",
       "10                         5                       3                      1   \n",
       "11                         2                       3                      2   \n",
       "12                         4                       3                      2   \n",
       "\n",
       "    Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0        17539.0                 2517          15022.0                 0.743   \n",
       "2         4964.0                 2316           2648.0                 0.793   \n",
       "4        13731.0                 1375          12356.0                 0.878   \n",
       "6         9815.0                 1699           8116.0                 0.620   \n",
       "7        32641.0                 1551          31090.0                 0.488   \n",
       "8        32056.0                 1887          30169.0                 0.831   \n",
       "9         1998.0                    0           1998.0                 0.717   \n",
       "10        8997.0                  708           8289.0                 0.586   \n",
       "11        7825.0                    0           7825.0                 0.724   \n",
       "12       34516.0                 1043          33473.0                 0.690   \n",
       "\n",
       "    Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0              1220              30                0.765   \n",
       "2              3279              66                0.941   \n",
       "4             14826              99                0.707   \n",
       "6              7962              89                0.561   \n",
       "7              1327              30                0.304   \n",
       "8              2730              68                0.700   \n",
       "9              4637              68                0.889   \n",
       "10             4558              62                0.676   \n",
       "11            14326             100                0.786   \n",
       "12             4654              59                0.639   \n",
       "\n",
       "    Avg_Utilization_Ratio  \n",
       "0                   0.144  \n",
       "2                   0.467  \n",
       "4                   0.100  \n",
       "6                   0.173  \n",
       "7                   0.048  \n",
       "8                   0.059  \n",
       "9                   0.000  \n",
       "10                  0.079  \n",
       "11                  0.000  \n",
       "12                  0.030  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer_Age</th>\n      <th>Gender</th>\n      <th>Dependent_count</th>\n      <th>Card_Category</th>\n      <th>Months_on_book</th>\n      <th>Total_Relationship_Count</th>\n      <th>Months_Inactive_12_mon</th>\n      <th>Contacts_Count_12_mon</th>\n      <th>Credit_Limit</th>\n      <th>Total_Revolving_Bal</th>\n      <th>Avg_Open_To_Buy</th>\n      <th>Total_Amt_Chng_Q4_Q1</th>\n      <th>Total_Trans_Amt</th>\n      <th>Total_Trans_Ct</th>\n      <th>Total_Ct_Chng_Q4_Q1</th>\n      <th>Avg_Utilization_Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>43</td>\n      <td>6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>17539.0</td>\n      <td>2517</td>\n      <td>15022.0</td>\n      <td>0.743</td>\n      <td>1220</td>\n      <td>30</td>\n      <td>0.765</td>\n      <td>0.144</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>27</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4964.0</td>\n      <td>2316</td>\n      <td>2648.0</td>\n      <td>0.793</td>\n      <td>3279</td>\n      <td>66</td>\n      <td>0.941</td>\n      <td>0.467</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Blue</td>\n      <td>38</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13731.0</td>\n      <td>1375</td>\n      <td>12356.0</td>\n      <td>0.878</td>\n      <td>14826</td>\n      <td>99</td>\n      <td>0.707</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>53</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Blue</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9815.0</td>\n      <td>1699</td>\n      <td>8116.0</td>\n      <td>0.620</td>\n      <td>7962</td>\n      <td>89</td>\n      <td>0.561</td>\n      <td>0.173</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>55</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>37</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>32641.0</td>\n      <td>1551</td>\n      <td>31090.0</td>\n      <td>0.488</td>\n      <td>1327</td>\n      <td>30</td>\n      <td>0.304</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>32</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>32056.0</td>\n      <td>1887</td>\n      <td>30169.0</td>\n      <td>0.831</td>\n      <td>2730</td>\n      <td>68</td>\n      <td>0.700</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>F</td>\n      <td>1</td>\n      <td>Blue</td>\n      <td>31</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1998.0</td>\n      <td>0</td>\n      <td>1998.0</td>\n      <td>0.717</td>\n      <td>4637</td>\n      <td>68</td>\n      <td>0.889</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44</td>\n      <td>M</td>\n      <td>3</td>\n      <td>Blue</td>\n      <td>34</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8997.0</td>\n      <td>708</td>\n      <td>8289.0</td>\n      <td>0.586</td>\n      <td>4558</td>\n      <td>62</td>\n      <td>0.676</td>\n      <td>0.079</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38</td>\n      <td>F</td>\n      <td>2</td>\n      <td>Blue</td>\n      <td>36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7825.0</td>\n      <td>0</td>\n      <td>7825.0</td>\n      <td>0.724</td>\n      <td>14326</td>\n      <td>100</td>\n      <td>0.786</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44</td>\n      <td>M</td>\n      <td>4</td>\n      <td>Silver</td>\n      <td>27</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>34516.0</td>\n      <td>1043</td>\n      <td>33473.0</td>\n      <td>0.690</td>\n      <td>4654</td>\n      <td>59</td>\n      <td>0.639</td>\n      <td>0.030</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "not_missing_X = not_missing_df.drop(columns=['Attrition_Flag', 'Education_Level', 'Marital_Status', 'Income_Category'], axis='columns')\n",
    "not_missing_y1 = not_missing_df['Education_Level']\n",
    "not_missing_y2 = not_missing_df['Marital_Status']\n",
    "not_missing_y3 = not_missing_df['Income_Category']\n",
    "\n",
    "not_missing_X.iloc[:10, :]"
   ]
  },
  {
   "source": [
    "### Training An Imputer Model\n",
    "\n",
    "Let's try a few different methods of imputing and pick the ones which have the best accuracy. We won't spend too much of our effort here since it is not the main task. \n",
    "\n",
    "The task here is a multi-class classification problem. First, let's get a baseline accuracy by just picking the most common categories for each feature. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most common education level: Graduate\nAccuracy: 0.36\n\nMost common marital status: Married\nAccuracy: 0.50\n\nMost common income category: Less than $40K\nAccuracy: 0.40\n\n"
     ]
    }
   ],
   "source": [
    "mode1 = not_missing_df['Education_Level'].mode()[0]\n",
    "mode2 = not_missing_df['Marital_Status'].mode()[0]\n",
    "mode3 = not_missing_df['Income_Category'].mode()[0]\n",
    "\n",
    "mode_score_1 = not_missing_df['Education_Level'].value_counts(normalize=True)[0]\n",
    "mode_score_2 = not_missing_df['Marital_Status'].value_counts(normalize=True)[0]\n",
    "mode_score_3 = not_missing_df['Income_Category'].value_counts(normalize=True)[0]\n",
    "\n",
    "print(f'Most common education level: {mode1}')\n",
    "print(f'Accuracy: {mode_score_1:.2f}\\n')\n",
    "print(f'Most common marital status: {mode2}')\n",
    "print(f'Accuracy: {mode_score_2:.2f}\\n')\n",
    "print(f'Most common income category: {mode3}')\n",
    "print(f'Accuracy: {mode_score_3:.2f}\\n')"
   ]
  },
  {
   "source": [
    "Next, let's try using random forests."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# This encoder is a restriction of the one we constructed above.\n",
    "imputer_encoder = make_column_transformer(\n",
    "                                (OneHotEncoder(drop='first'), \n",
    "                                 ['Gender']),\n",
    "                                (OrdinalEncoder(categories=[['Blue', 'Silver', 'Gold', 'Platinum']]), \n",
    "                                 ['Card_Category']),\n",
    "                                remainder='passthrough')\n",
    "\n",
    "forest1 = RandomForestClassifier(random_state=808)\n",
    "forest2 = RandomForestClassifier(random_state=808)\n",
    "forest3 = RandomForestClassifier(random_state=808)\n",
    "\n",
    "param_grid = {'forest__n_estimators':range(1, 50),\n",
    "              'forest__max_depth':range(1, 20),\n",
    "              'forest__max_features':range(1, 10)}\n",
    "\n",
    "forest_pipe1 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest1)])\n",
    "forest_pipe2 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest2)])\n",
    "forest_pipe3 = Pipeline([('encoder', imputer_encoder), ('scaler', scaler), ('forest', forest3)])\n",
    "\n",
    "forest_grid1=RandomizedSearchCV(forest_pipe1, param_grid, cv=5, scoring='accuracy')\n",
    "forest_grid2=RandomizedSearchCV(forest_pipe2, param_grid, cv=5, scoring='accuracy')\n",
    "forest_grid3=RandomizedSearchCV(forest_pipe3, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "forest_grid1.fit(not_missing_X, not_missing_y1)\n",
    "forest_grid2.fit(not_missing_X, not_missing_y2)\n",
    "forest_grid3.fit(not_missing_X, not_missing_y3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Education Level\nAccuracy: 0.36\nBest params: {'forest__n_estimators': 25, 'forest__max_features': 6, 'forest__max_depth': 1}\n\nMarital Status\nAccuracy: 0.56\nBest params: {'forest__n_estimators': 31, 'forest__max_features': 9, 'forest__max_depth': 18}\n\nIncome Category\nAccuracy: 0.59\nBest params: {'forest__n_estimators': 31, 'forest__max_features': 9, 'forest__max_depth': 12}\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "forest_score1 = forest_grid1.best_score_\n",
    "forest_score2 = forest_grid2.best_score_\n",
    "forest_score3 = forest_grid3.best_score_\n",
    "\n",
    "forest_params1 = forest_grid1.best_params_\n",
    "forest_params2 = forest_grid2.best_params_\n",
    "forest_params3 = forest_grid3.best_params_\n",
    "\n",
    "print(f'Education Level\\nAccuracy: {forest_score1:.2f}\\nBest params: {forest_params1}\\n')\n",
    "print(f'Marital Status\\nAccuracy: {forest_score2:.2f}\\nBest params: {forest_params2}\\n')\n",
    "print(f'Income Category\\nAccuracy: {forest_score3:.2f}\\nBest params: {forest_params3}\\n')"
   ]
  },
  {
   "source": [
    "The results are a slight improvement from our baseline. \n",
    "\n",
    "Let's see how an SGD classifier performs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Baseline Model\n",
    "\n",
    "Let's quickly train a logistic regression model to get a good baseline before we start using dimensionality reduction techniques. This way, we will be able to run sanity checks and see if our tehcniques are working towards improving the model or not."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "logreg.fit(train_X, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4453846153846154"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "cross_val_score(logreg, train_X, train_y, scoring='recall', cv=10).mean()"
   ]
  },
  {
   "source": [
    "## Feature Selection\n",
    "\n",
    "Here, we will attempt to apply some dimensionality reduction techniques, with a focus on maintaining the explainability of our future model. At the core, our task is to solve a binary classification problem using a mix of categorical and numerical data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "We will compare each of our features to our target variable. If the feature is of integer type, we will apply the $\\chi^2$ test. For features of float type, we will perform an Analysis of Variance (ANOVA)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Customer_Age',\n",
       " 'Gender',\n",
       " 'Dependent_count',\n",
       " 'Education_Level',\n",
       " 'Income_Category',\n",
       " 'Card_Category',\n",
       " 'Months_on_book',\n",
       " 'Total_Relationship_Count',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Contacts_Count_12_mon',\n",
       " 'Total_Revolving_Bal',\n",
       " 'Total_Trans_Amt',\n",
       " 'Total_Trans_Ct',\n",
       " 'Divorced',\n",
       " 'Married',\n",
       " 'Single']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from pandas.api.types import is_integer_dtype\n",
    "\n",
    "int_cols = []\n",
    "num_cols = \n",
    "\n",
    "int_cols = [c for c in train_X.columns if is_integer_dtype(train_X[c])]\n",
    "int_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p-value Statistics:\n\nCustomer_Age: 0.00018754729896914405\nFeature is probably independent of target: False\n\nGender: 0.0019387268628536134\nFeature is probably independent of target: False\n\nDependent_count: 0.11853926182350483\nFeature is probably independent of target: True\n\nEducation_Level: 0.13604314302570286\nFeature is probably independent of target: True\n\nIncome_Category: 0.033668678227946586\nFeature is probably independent of target: False\n\nCard_Category: 0.9969557126182217\nFeature is probably independent of target: True\n\nMonths_on_book: 0.0072873588005836374\nFeature is probably independent of target: False\n\nTotal_Relationship_Count: 3.756870908123146e-27\nFeature is probably independent of target: False\n\nMonths_Inactive_12_mon: 1.0826609625096649e-20\nFeature is probably independent of target: False\n\nContacts_Count_12_mon: 8.622028303171061e-41\nFeature is probably independent of target: False\n\nTotal_Revolving_Bal: 0.0\nFeature is probably independent of target: False\n\nTotal_Trans_Amt: 0.0\nFeature is probably independent of target: False\n\nTotal_Trans_Ct: 0.0\nFeature is probably independent of target: False\n\nDivorced: 0.5853203390581991\nFeature is probably independent of target: True\n\nMarried: 0.23936404094514024\nFeature is probably independent of target: True\n\nSingle: 0.34414046037950574\nFeature is probably independent of target: True\n\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_values = chi2(train_X[int_cols], train_y)[1]\n",
    "col_filter = {}\n",
    "\n",
    "print('p-value Statistics:\\n')\n",
    "for i in range(len(int_cols)):\n",
    "    feature = int_cols[i]\n",
    "    p = p_values[i]\n",
    "\n",
    "    print(f'{feature}: {p:.2f}')\n",
    "\n",
    "    is_independent = False if p <= alpha else True\n",
    "    col_filter[feature] = not is_independent    # Will throw away features which are independent from the target.\n",
    "\n",
    "    print(f'Feature is probably independent of target: {is_independent}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}